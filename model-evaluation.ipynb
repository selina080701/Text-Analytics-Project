{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Evaluation",
   "id": "72e3ea9537f4eb12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Imports and Setup\n",
    "## 1.1 Import Libraries"
   ],
   "id": "e62f7d2f325e465b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2 Load Data",
   "id": "870d8602cd6d84cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "GENRE_COL = \"tag\"\n",
    "\n",
    "df = pd.read_csv(\"data/clean/data.csv\")\n",
    "\n",
    "# Filter to English only (same as in your other notebook)\n",
    "df = df[df[\"language_cld3\"] == \"en\"].reset_index(drop=True)\n",
    "\n",
    "# Ensure tokens are lists\n",
    "if isinstance(df[\"tokens\"].iloc[0], str):\n",
    "    df[\"tokens\"] = df[\"tokens\"].apply(ast.literal_eval)\n",
    "\n",
    "df = df.dropna(subset=[\"tokens\", GENRE_COL]).reset_index(drop=True)\n",
    "\n",
    "print(df[[GENRE_COL, \"tokens\"]].head())\n",
    "print(\"Number of songs:\", len(df))"
   ],
   "id": "3180bcc6b72d3f2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.3 Load Word2Vec-Model",
   "id": "4a0c46d437dd981"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "w2v_model = Word2Vec.load(\"models/word2vec_lyrics.model\")\n",
    "print(\"Loaded Word2Vec model with vector size:\", w2v_model.vector_size)"
   ],
   "id": "5d709fcaeb4496c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Embedding models\n",
    "\n",
    "In diesem Abschnitt vergleichen wir verschiedene Repräsentationen der Songtexte:\n",
    "\n",
    "2.1 **Word2Vec (mean)** – Durchschnitt der Wortvektoren pro Song\n",
    "2.2 **TF-IDF (Bag-of-Words)** – klassische sparse Repräsentation\n",
    "2.3 **Sentence Transformer** – moderne vortrainierte Text-Embeddings\n",
    "\n",
    "Für jede Repräsentation trainieren wir eine logistische Regression mit `class_weight='balanced'` und evaluieren sie mit Accuracy, Balanced Accuracy und einer Confusion Matrix."
   ],
   "id": "e2aea37daa7346cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix\"):\n",
    "    \"\"\"\n",
    "    Nicely formatted confusion matrix using seaborn.\n",
    "    Expects a normalized matrix (values in [0,1]).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"viridis\",          # same look as im text-classification notebook\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        square=True,\n",
    "        cbar_kws={\"shrink\": 0.8},\n",
    "    )\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "e15a75e0a3cb650",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_and_evaluate_representation(name, X, labels, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Train and evaluate a balanced Logistic Regression on given features.\n",
    "    Returns metrics and trained objects.\n",
    "    \"\"\"\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(labels)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced\",\n",
    "        multi_class=\"auto\",\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    bacc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy:          {acc:.3f}\")\n",
    "    print(f\"Balanced accuracy: {bacc:.3f}\\n\")\n",
    "    print(\"Classification report:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "    # Normalisierte Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "    plot_confusion_matrix(\n",
    "        cm_norm,\n",
    "        class_names=le.classes_,\n",
    "        title=f\"Normalized Confusion Matrix – {name}\",\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"balanced_accuracy\": bacc,\n",
    "        \"clf\": clf,\n",
    "        \"label_encoder\": le,\n",
    "    }\n",
    "\n",
    "\n",
    "results = []  # to collect all experiments"
   ],
   "id": "57d181a88d0f6ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.1 Word2Vec (mean)\n",
    "\n",
    "Hier bilden wir für jeden Song den Durchschnitt aller Word2Vec-Vektoren der enthaltenen Tokens.\n",
    "Das ergibt einen dichten, niedrigen Dokumentvektor pro Song."
   ],
   "id": "948c3618f2f17d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_mean_w2v_embeddings(df_in, model, token_col=\"tokens\"):\n",
    "    \"\"\"Compute simple mean Word2Vec document embeddings.\"\"\"\n",
    "    dim = model.wv.vector_size\n",
    "    doc_emb = np.zeros((len(df_in), dim), dtype=np.float32)\n",
    "\n",
    "    for i, tokens in enumerate(df_in[token_col]):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            continue\n",
    "        vectors = [model.wv[t] for t in tokens if t in model.wv]\n",
    "        if vectors:\n",
    "            doc_emb[i] = np.mean(vectors, axis=0).astype(np.float32)\n",
    "\n",
    "    keep = np.linalg.norm(doc_emb, axis=1) > 0\n",
    "    return doc_emb[keep], df_in.loc[keep].reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_w2v_mean, df_w2v_mean = build_mean_w2v_embeddings(df, w2v_model)\n",
    "labels_w2v_mean = df_w2v_mean[GENRE_COL].astype(str).values\n",
    "\n",
    "res_w2v_mean = train_and_evaluate_representation(\n",
    "    \"Word2Vec (mean)\", X_w2v_mean, labels_w2v_mean\n",
    ")\n",
    "results.append(res_w2v_mean)"
   ],
   "id": "44c49675ec6d588b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2 TF-IDF (Bag-of-Words)\n",
    "\n",
    "Als klassische Textrepräsentation verwenden wir hier ein TF-IDF-Vektormodell auf Wortebene.\n",
    "Jeder Song wird durch einen hochdimensionalen, sparse Vektor beschrieben, der die Wichtigkeit von Wörtern im Song relativ zum Korpus widerspiegelt."
   ],
   "id": "bd21ba50ed146cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Build plain text strings from tokens\n",
    "df[\"lyrics_text\"] = df[\"tokens\"].apply(lambda toks: \" \".join(toks))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,  # optional: limit vocab size\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df[\"lyrics_text\"])\n",
    "labels_tfidf = df[GENRE_COL].astype(str).values\n",
    "\n",
    "# Note: X_tfidf is sparse; LogisticRegression can handle that.\n",
    "res_tfidf = train_and_evaluate_representation(\n",
    "    \"TF-IDF (bag-of-words)\", X_tfidf, labels_tfidf\n",
    ")\n",
    "results.append(res_tfidf)"
   ],
   "id": "fb49a5a2ce77a69b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.3 Sentence Transformer\n",
    "\n",
    "Hier verwenden wir ein vortrainiertes Sentence-Transformer-Modell (`all-MiniLM-L6-v2`),\n",
    "das ganze Sätze bzw. Dokumente direkt in semantische Vektoren im hochdimensionalen Raum einbettet.\n",
    "Diese Repräsentation ist deutlich stärker als selbsttrainiertes Word2Vec und reicht oft nah an den Stand der Technik für Textklassifikation heran.\n"
   ],
   "id": "c2b0ac38f6147f33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "st_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# We can reuse df[\"lyrics_text\"] from the TF-IDF step\n",
    "texts_st = df[\"lyrics_text\"].tolist()\n",
    "labels_st = df[GENRE_COL].astype(str).values\n",
    "\n",
    "X_st = st_model.encode(\n",
    "    texts_st,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    ")\n",
    "\n",
    "res_st = train_and_evaluate_representation(\n",
    "    \"SentenceTransformer (all-MiniLM-L6-v2)\", X_st, labels_st\n",
    ")\n",
    "results.append(res_st)\n"
   ],
   "id": "3047758810addbce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Vergleich der Embedding-Modelle\n",
    "\n",
    "Zum Abschluss vergleichen wir die drei Ansätze anhand der Balanced Accuracy."
   ],
   "id": "8b5d3a5b01f4d89b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_names = [r[\"name\"] for r in results]\n",
    "balanced_accs = [r[\"balanced_accuracy\"] for r in results]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(model_names, balanced_accs)\n",
    "plt.ylabel(\"Balanced accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.title(\"Comparison of embedding models\")\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bar, val in zip(bars, balanced_accs):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        bar.get_height() + 0.01,\n",
    "        f\"{val:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "786e1bb0d71d8769",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
