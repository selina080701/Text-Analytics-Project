{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation\n",
    "\n",
    "---"
   ],
   "id": "42ec20fb487549b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Imports and Setup\n",
    "## 1.1 Import Libraries"
   ],
   "id": "e2dfd8e630082a5a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "import re\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "print(np.__version__)\n",
    "print(torch.__version__)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2 Load Data",
   "id": "e5085d51fa43051"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"data/clean/data.csv\")\n",
    "\n",
    "df[\"tokens\"] = df[\"tokens\"].apply(ast.literal_eval)\n",
    "texts = df[\"tokens\"]\n",
    "labels = df[\"tag\"]\n",
    "\n",
    "print(df['tokens'].head())\n",
    "print(type(df[\"tokens\"].iloc[0]))"
   ],
   "id": "67858ecc99e06e04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.3 Encode labels",
   "id": "1c97f3aecd90ce5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Encode string labels (genres) into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "print(\"Classes (genres):\")\n",
    "for idx, cls in enumerate(label_encoder.classes_):\n",
    "    print(f\"{idx}: {cls}\")"
   ],
   "id": "1ee0089525ff69c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Model\n",
    "## 2.1 Train-Test-Split"
   ],
   "id": "dde09e8f5044f4fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_texts, X_test_texts, y_train, y_test = train_test_split(\n",
    "    texts,\n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded,\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train_texts.shape[0])\n",
    "print(\"Test size:\", X_test_texts.shape[0])"
   ],
   "id": "17d8b1d2be4a655b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 Embedding (Word2Vec)",
   "id": "990486be76f8e2e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_tokens = X_train_texts.tolist() # list of lists\n",
    "X_test_tokens  = X_test_texts.tolist()"
   ],
   "id": "dbf1e981b9f2b88b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "w2v = Word2Vec(\n",
    "    sentences=X_train_tokens,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=4,\n",
    "    sg=1,\n",
    "    epochs=10,\n",
    ")\n",
    "\n",
    "print(\"Vocabulary size:\", len(w2v.wv))"
   ],
   "id": "64085d0f8fd6c988",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def embed_sentence(tokens, model):\n",
    "    vectors = [model.wv[w] for w in tokens if w in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "X_train_emb = np.vstack([embed_sentence(toks, w2v) for toks in X_train_tokens])\n",
    "X_test_emb  = np.vstack([embed_sentence(toks, w2v) for toks in X_test_tokens])\n",
    "\n",
    "print(\"X_train_emb shape:\", X_train_emb.shape)\n",
    "print(\"X_test_emb shape:\", X_test_emb.shape)"
   ],
   "id": "d957d27553b76f84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2.1 Train Classification-Model (LinearSVC)",
   "id": "461f9c0bc1d1655a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "clf_w2v_svc = LinearSVC(class_weight=\"balanced\", max_iter=10000)\n",
    "clf_w2v_svc.fit(X_train_emb, y_train)"
   ],
   "id": "65f27397fc5dcd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred_w2v_svc = clf_w2v_svc.predict(X_test_emb)\n",
    "\n",
    "print(\"=== Word2Vec + LinearSVC ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_w2v_svc))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_test, y_pred_w2v_svc))\n",
    "print(classification_report(y_test, y_pred_w2v_svc, target_names=label_encoder.classes_))"
   ],
   "id": "cfd3a848aaf1630f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_test, y_pred_w2v_svc, labels=label_encoder.transform(label_encoder.classes_))\n",
    "\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(\n",
    "    cm_norm,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Normalized Confusion Matrix – Word2Vec + LinearSVC\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "914f774069024b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2.2 Train Classification-Model (Logistic Regression)",
   "id": "495467d065551bd2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "clf_w2v_logreg = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "clf_w2v_logreg.fit(X_train_emb, y_train)"
   ],
   "id": "c7ccf1d3f227079a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred_w2v_logreg = clf_w2v_logreg.predict(X_test_emb)\n",
    "\n",
    "print(\"=== Word2Vec + Logistic Regression ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_w2v_logreg))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_test, y_pred_w2v_logreg))\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test, y_pred_w2v_logreg, target_names=label_encoder.classes_))"
   ],
   "id": "957785796769a793",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_test, y_pred_w2v_logreg, labels=label_encoder.transform(label_encoder.classes_))\n",
    "\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(\n",
    "    cm_norm,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Normalized Confusion Matrix – Word2Vec + Logistic Regression\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "685a75583e36ff59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Word2Vec + LinearSVC**\n",
    "\n",
    "    - Accuracy: ~0.574\n",
    "    - Balanced Accuracy: ~0.502\n",
    "\n",
    "**Word2Vec + Logistic Regression**\n",
    "\n",
    "    - Accuracy: ~0.465\n",
    "    - Balanced Accuracy: ~0.555\n",
    "\n",
    "The Word2Vec experiments show clear differences between the two classifiers. LinearSVC performs best overall, reaching an accuracy of about 57% and a balanced accuracy of 50%. It handles the dominant genres (rap and pop) well, but struggles with smaller classes, which is expected given their limited representation.\n",
    "\n",
    "Logistic Regression, in contrast, achieves a lower overall accuracy of around 46%, but a slightly higher balanced accuracy of 55%. This indicates that it distributes attention more evenly across genres and performs better on minority classes such as country, misc, and rb. However, it has difficulty separating the larger and semantically similar classes, particularly pop, which reduces its overall performance.\n",
    "\n",
    "In summary, LinearSVC is the stronger classifier for Word2Vec embeddings, while Logistic Regression provides a more balanced but less accurate alternative."
   ],
   "id": "24d037b32703db3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 Embedding (TF-IDF)",
   "id": "c899ba2b2bc3eefd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_texts_char = X_train_texts.apply(lambda toks: \" \".join(toks))\n",
    "X_test_texts_char  = X_test_texts.apply(lambda toks: \" \".join(toks))"
   ],
   "id": "57d41b69af9eb7a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=5,\n",
    "    max_df=0.9,\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_texts_char)\n",
    "X_test_tfidf  = tfidf.transform(X_test_texts_char)"
   ],
   "id": "82bc9d7e6cf8d33f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3.1 Train Classification-Model (LinearSVC)",
   "id": "72628c1ac04bffbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "clf_tfidf_svc = LinearSVC(class_weight='balanced')\n",
    "clf_tfidf_svc.fit(X_train_tfidf, y_train)"
   ],
   "id": "90cbf541d09e89e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred_tfidf_svc = clf_tfidf_svc.predict(X_test_tfidf)\n",
    "\n",
    "print(\"=== TF-IDF + LinearSVC ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf_svc))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_test, y_pred_tfidf_svc))\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test, y_pred_tfidf_svc, target_names=label_encoder.classes_))"
   ],
   "id": "17e1bbc734e7e804",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_test, y_pred_tfidf_svc, labels=label_encoder.transform(label_encoder.classes_))\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(\n",
    "    cm_norm,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Normalized Confusion Matrix – TF-IDF + LinearSVC\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f7ab4a81f253f1c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3.2 Train Classification-Model (Logistic Regression)",
   "id": "3a5435069a5e97f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "clf_tfidf_logreg = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "clf_tfidf_logreg.fit(X_train_tfidf, y_train)"
   ],
   "id": "6e8b8ef83b7366e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred_tfidf_logreg = clf_tfidf_logreg.predict(X_test_tfidf)\n",
    "\n",
    "print(\"=== TF-IDF + Logistic Regression ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf_logreg))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_test, y_pred_tfidf_logreg))\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test, y_pred_tfidf_logreg, target_names=label_encoder.classes_))"
   ],
   "id": "c6f7ffe0a68b5c02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_test, y_pred_tfidf_logreg, labels=label_encoder.transform(label_encoder.classes_))\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(\n",
    "    cm_norm,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Normalized Confusion Matrix – TF-IDF + Logistic Regression\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c5b11cc552bfdb56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**TF-IDF + LinearSVC**\n",
    "\n",
    "    - Accuracy: ~0.59\n",
    "    - Balanced Accuracy: ~0.46\n",
    "\n",
    "**TF-IDF + Logistic Regression**\n",
    "\n",
    "    - Accuracy: ~0.55\n",
    "    - Balanced Accuracy: ~0.53\n",
    "\n",
    "With TF-IDF embeddings, LinearSVC achieves the highest overall accuracy, driven mainly by strong performance on the dominant genres such as rap and pop. However, its lower balanced accuracy shows that minority genres are classified less reliably.\n",
    "\n",
    "Logistic Regression performs slightly worse in overall accuracy but achieves a higher balanced accuracy, indicating better handling of smaller genres like country, misc, and rb. It distributes predictions more evenly across classes but struggles with the large and overlapping genres, especially pop.\n",
    "\n",
    "In summary, LinearSVC offers the best overall performance with TF-IDF, while Logistic Regression provides a more balanced but slightly weaker alternative."
   ],
   "id": "1fd5d00f1aa0229e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.4 Embedding (Transformer)\n",
    "\n",
    "SentenceTransformer-models (z.B. all-MiniLM-L6-v2) are based on Transformer-Backbones. These models have an integrated and trained tokenization-pipeline. haben bereits eine integrierte, trainierte Tokenizer-Pipeline.\n",
    "\n",
    "The command `model.to(\"cpu\")` forces the SentenceTransformer model to run on the CPU instead of the GPU. It is useful when GPU memory is limited or the system becomes unstable during encoding. By moving the model to the CPU, the computations become slower but more stable and require less specialized hardware resources."
   ],
   "id": "91c671ef58542bcf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")",
   "id": "7e04989659dc01f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_sent = [\" \".join(toks) for toks in X_train_texts]\n",
    "X_test_sent  = [\" \".join(toks) for toks in X_test_texts]"
   ],
   "id": "f53b16668af0e457",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_emb_st = model.encode(\n",
    "    X_train_sent,\n",
    "    batch_size=16,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=False,\n",
    "    convert_to_tensor=True,\n",
    ")\n",
    "\n",
    "X_test_emb_st = model.encode(\n",
    "    X_test_sent,\n",
    "    batch_size=16,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=False,\n",
    "    convert_to_tensor=True,\n",
    ")\n",
    "\n",
    "print(\"Shapes:\", X_train_emb_st.shape, X_test_emb_st.shape)"
   ],
   "id": "6be90610bdb98091",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_emb_st = X_train_emb_st.tolist()\n",
    "X_test_emb_st  = X_test_emb_st.tolist()"
   ],
   "id": "ff882d1da121665a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.4.1 Train Classification-Model (LinearSVC)",
   "id": "f5726900e177234c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "clf_st_svc = LinearSVC(class_weight=\"balanced\", max_iter=10000)\n",
    "clf_st_svc.fit(X_train_emb_st, y_train)"
   ],
   "id": "cd97007f207079cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred_st_svc = clf_st_svc.predict(X_test_emb_st)\n",
    "\n",
    "print(\"=== SentenceTransformer (MiniLM) + LinearSVC ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_st_svc))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_test, y_pred_st_svc))\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test,y_pred_st_svc,\n",
    "                            labels=np.arange(len(label_encoder.classes_)),\n",
    "                            target_names=label_encoder.classes_))"
   ],
   "id": "bd3cb706ad2dc746",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_test, y_pred_st_svc, labels=np.arange(len(label_encoder.classes_)))\n",
    "\n",
    "cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(\n",
    "    cm_norm,\n",
    "    annot=True,\n",
    "    cmap=\"Blues\",\n",
    "    fmt=\".2f\",\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_,\n",
    ")\n",
    "plt.title(\"SentenceTransformer (MiniLM) + LinearSVC\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5579036e2ab0477f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.4.2 Train Classification-Model (Logistic Regression)",
   "id": "4e0f70671f44edb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "clf_st_logreg = LogisticRegression(\n",
    "    max_iter=3000,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\",\n",
    "    multi_class=\"auto\",\n",
    ")\n",
    "\n",
    "clf_st_logreg.fit(X_train_emb_st, y_train)"
   ],
   "id": "3b29461cc437b5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred_st_logreg = clf_st_logreg.predict(X_test_emb_st)\n",
    "\n",
    "print(\"=== SentenceTransformer (MiniLM) + Logistic Regression ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_st_logreg))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_test, y_pred_st_logreg))\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test, y_pred_st_logreg,\n",
    "                            labels=np.arange(len(label_encoder.classes_)),\n",
    "                            target_names=label_encoder.classes_))"
   ],
   "id": "5fb0831f98169812",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_test, y_pred_st_logreg, labels=np.arange(len(label_encoder.classes_)))\n",
    "\n",
    "cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(\n",
    "    cm_norm,\n",
    "    annot=True,\n",
    "    cmap=\"Blues\",\n",
    "    fmt=\".2f\",\n",
    "    xticklabels=label_encoder.classes_,\n",
    "    yticklabels=label_encoder.classes_,\n",
    ")\n",
    "plt.title(\"SentenceTransformer (MiniLM) + Logistic Regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f0d5adfd62715578",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Model Comparison Overview",
   "id": "2ab1486a9a36c0c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Embedding | Classifier | Accuracy | Balanced Accuracy | Interpretation |\n",
    "|-----------|------------|----------|-------------------|----------------|\n",
    "| **Word2Vec** | LinearSVC | ~0.57 | ~0.50 | Strongest Word2Vec model; good for dominant genres, limited minority class performance |\n",
    "| **Word2Vec** | Logistic Regression | ~0.46 | ~0.55 | Most balanced across genres; high recall for small classes but low accuracy for major ones |\n",
    "| **TF-IDF** | LinearSVC | ~0.59 | ~0.46 | Best overall performance for TF-IDF; strong on major genres, weaker on minority classes |\n",
    "| **TF-IDF** | Logistic Regression | ~0.55 | ~0.53 | More balanced across genres; better recall on smaller classes but weaker on pop |"
   ],
   "id": "8ecef29949f7664f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
