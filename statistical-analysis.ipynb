{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "386dba31b3837c61",
   "metadata": {},
   "source": [
    "# Statistical Analysis: Genius Song Lyrics Subset (1%)\n",
    "\n",
    "**Dataset:** 34'049 Songs | 26'408 Artists | 6 Genres\n",
    "\n",
    "**Genres:**\n",
    "* Rap / Hip-Hop\n",
    "* Rock\n",
    "* Pop\n",
    "* R&B (Rhythm and Blues)\n",
    "* Country\n",
    "* Miscellaneous (various other genres)\n",
    "\n",
    "**Purpose:** Explore statistical patterns in song lyrics across genres and artists. This includes descriptive statistics of the dataset, word-level metrics (vocabulary size, word frequency distributions, Zipf’s law), and n-gram analyses to examine stylistic and linguistic patterns.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735f3a7ca3023a7",
   "metadata": {},
   "source": [
    "# 1. Dataset Overview\n",
    "## 1.1 Import Packages and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c43beab6da3f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import tee\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b19b53bba2d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b626abee835f0c0",
   "metadata": {},
   "source": [
    "## 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872a13cff553462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean/data.csv')\n",
    "\n",
    "# convert string representations of lists back into actual Python lists\n",
    "for col in [\"words\", \"tokens\"]:\n",
    "    if isinstance(df[col].iloc[0], str):\n",
    "        df[col] = df[col].apply(ast.literal_eval)\n",
    "\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"Number of Songs: {len(df)} | Artists: {df['artist'].nunique()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d30aa55421d63",
   "metadata": {},
   "source": [
    "## 1.3 Descriptive Statistics\n",
    "Before diving deeper into the analysis, we start with some basic descriptive statistics. First, we examine the genre distribution within the dataset. Then, we analyze characteristics of the lyrics themselves — such as the total number of lyrics and words, as well as the average, minimum, and maximum word counts — both before and after removing stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d1b4d6c58b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre distribution\n",
    "print(\"\\nGENRE DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "category_counts = df['tag'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "for tag,count in category_counts.items():\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"{tag}: {count:,} songs ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a5a4bea5d6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts.plot(kind=\"bar\")\n",
    "plt.title(\"Genre Distribution\", fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e5acb85a6d3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lyrics = len(df)\n",
    "total_words_raw = df[\"word_count\"].sum()\n",
    "avg_words_raw = df[\"word_count\"].mean()\n",
    "min_words_raw = df[\"word_count\"].min()\n",
    "max_words_raw = df[\"word_count\"].max()\n",
    "\n",
    "print(\"TEXT STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total lyrics (songs):     {total_lyrics:,}\")\n",
    "print(f\"Total words:              {total_words_raw:,}\")\n",
    "print(f\"Average words/lyric:      {avg_words_raw:.2f}\")\n",
    "print(f\"Shortest lyric:           {min_words_raw} words\")\n",
    "print(f\"Longest lyric:            {max_words_raw} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d878569e14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_row = df[\"tokens\"]\n",
    "tokens = [t for row in tokens_per_row for t in row]\n",
    "\n",
    "total_lyrics = len(df)\n",
    "total_tokens = len(tokens)\n",
    "unique_tokens = len(set(tokens))\n",
    "avg_tokens = df[\"token_count\"].mean()\n",
    "min_tokens = df[\"token_count\"].min()\n",
    "max_tokens = df[\"token_count\"].max()\n",
    "\n",
    "print(\"TOKEN STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total lyrics (songs):     {total_lyrics:,}\")\n",
    "print(f\"Total tokens:             {total_tokens:,}\")\n",
    "print(f\"Unique tokens:            {unique_tokens:,}\")\n",
    "print(f\"Average tokens/lyric:     {avg_tokens:.2f}\")\n",
    "print(f\"Shortest lyric:           {min_tokens} tokens\")\n",
    "print(f\"Longest lyric:            {max_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee49895f6c0f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 15\n",
    "words = [t for row in df[\"words\"] for t in row]\n",
    "tokens_filtered = [t for row in df[\"tokens\"] for t in row]\n",
    "\n",
    "word_counts_raw = Counter(words).most_common(top_n)\n",
    "word_counts_filtered = Counter(tokens_filtered).most_common(top_n)\n",
    "\n",
    "df_raw = pd.DataFrame(word_counts_raw, columns=[\"word\", \"count\"])\n",
    "df_filtered = pd.DataFrame(word_counts_filtered, columns=[\"word\", \"count\"])\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "axes[0].bar(df_raw[\"word\"], df_raw[\"count\"])\n",
    "axes[0].set_title(f\"Top {top_n} Words (Before Stopword Removal)\", fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "axes[1].bar(df_filtered[\"word\"], df_filtered[\"count\"])\n",
    "axes[1].set_title(f\"Top {top_n} Words (After Stopword Removal)\", fontsize=12, fontweight='bold')\n",
    "axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a49d4a0428420",
   "metadata": {},
   "source": [
    "The plots above show the frequency of the 15 most common words before and after removing stopwords. We can clearly see that removing stopwords makes a significant difference: the most frequent word after filtering does not even appear among the top 15 words before stopword removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f61066d005a5ff",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Word-Level Analysis\n",
    "\n",
    "Now we take a deeper look at the lyrics and words by analyzing the vocabulary, examining Zipf’s law, identifying rare words (hapax legomena), and exploring various category statistics.\n",
    "\n",
    "## 2.1 Vocabulary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6db6743420f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all words\n",
    "all_tokens = [token for tokens in df[\"words\"] for token in tokens]\n",
    "\n",
    "# count unique words\n",
    "word_counts = Counter(all_tokens)\n",
    "vocab_size = len(word_counts)\n",
    "type_token_ratio = vocab_size / len(all_tokens)\n",
    "\n",
    "print(\"VOCABULARY STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total word tokens:          {len(all_tokens):,}\")\n",
    "print(f\"Unique words (vocabulary):  {vocab_size:,}\")\n",
    "print(f\"Type-token ratio:           {type_token_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e33e902a37c8f8b",
   "metadata": {},
   "source": [
    "On average, each word appears roughly 100 times in the dataset, indicating a high level of repetition.\n",
    "\n",
    "The type–token ratio (TTR) of 0.012 is relatively low, which was to be expected since the corpus consists of song lyrics — a genre characterized by recurring words, refrains, and limited lexical variety compared to other types of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06806d883157f95",
   "metadata": {},
   "source": [
    "## 2.2 Zipf's Law Analysis\n",
    "\n",
    "**Zipf's Law:** In natural language, word frequency is inversely proportional to rank.\n",
    "\n",
    "Mathematical form: **f(r) = C / r^α**\n",
    "\n",
    "Where:\n",
    "- f(r) = frequency at rank r\n",
    "- α = slope (ideal = -1.0 for natural language)\n",
    "- C = coefficient\n",
    "\n",
    "If α = -1.0, then rank 2 word appears half as often as rank 1, rank 3 appears 1/3 as often, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfcf78250f3595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_freq = Counter(words).most_common(100)\n",
    "ranks = list(range(1, len(all_word_freq) + 1))\n",
    "frequencies = [freq for word, freq in all_word_freq]\n",
    "\n",
    "# Fit power law model (top 100 words)\n",
    "log_ranks_100 = np.log(ranks).reshape(-1, 1)\n",
    "log_freq_100 = np.log(frequencies)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(log_ranks_100, log_freq_100)\n",
    "\n",
    "r_squared = model.score(log_ranks_100, log_freq_100)\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "coefficient_C = np.exp(intercept)\n",
    "\n",
    "print(\"ZIPF'S LAW ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Fitted equation: f(r) = {coefficient_C:.2f} / r^{abs(slope):.3f}\")\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Slope (α):         {slope:.4f}\")\n",
    "print(f\"  R^2 (fit quality): {r_squared:.4f}\")\n",
    "print(f\"  Ideal Zipf slope:  -1.0000\")\n",
    "print(f\"  Deviation:         {abs(slope + 1.0):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e778e724e6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Log-log plot\n",
    "axes[0].loglog(ranks, frequencies, 'o', alpha=0.7, color='steelblue', label='Actual')\n",
    "fitted_zipf = [coefficient_C / (r ** abs(slope)) for r in ranks]\n",
    "axes[0].loglog(ranks, fitted_zipf, 'g-', linewidth=2, alpha=0.8, label=f'Fitted (α={abs(slope):.3f})')\n",
    "ideal_zipf = [frequencies[0] / r for r in ranks]\n",
    "axes[0].loglog(ranks, ideal_zipf, 'r--', linewidth=2, alpha=0.7, label='Ideal Zipf (α=1.0)')\n",
    "axes[0].set_xlabel('Rank (log scale)')\n",
    "axes[0].set_ylabel('Frequency (log scale)')\n",
    "axes[0].set_title(\"Zipf's Law: Actual vs Fitted vs Ideal\", fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Top 30 comparison\n",
    "n = 30\n",
    "axes[1].plot(ranks[:n], frequencies[:n], 'o', color='steelblue', label='Actual')\n",
    "axes[1].plot(ranks[:n], [coefficient_C / (r ** abs(slope)) for r in ranks[:n]],\n",
    "             'g-', label=f'Fitted (α={abs(slope):.3f})', linewidth=2, alpha=0.7)\n",
    "axes[1].plot(ranks[:n], [frequencies[0] / r for r in ranks[:n]],\n",
    "             'r--', label='Ideal Zipf (a=1.0)', linewidth=2, alpha=0.6)\n",
    "axes[1].set_xlabel('Rank')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Top 30 Words: Detailed Comparison', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d82bc7d4c61d45",
   "metadata": {},
   "source": [
    "The fitted Zipf’s Law model shows a slope of −0.83 with an $R^2$ of 0.98, indicating an excellent fit to the expected distribution.\n",
    "\n",
    "Although the slope is slightly flatter than the ideal −1.0, this small deviation (0.17) suggests that the frequency–rank relationship in the lyrics follows Zipf’s Law closely — common words are used much more frequently than rare ones, as typically observed in song lyrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69f557d036935",
   "metadata": {},
   "source": [
    "## 2.3 Hapax Legomena (Rare Words)\n",
    "\n",
    "**Hapax legomena** = words appearing only once in the corpus\n",
    "\n",
    "These are the rarest words. High hapax count suggests diverse vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee8f23e44d04d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find hapax legomena\n",
    "word_counts = Counter(words)\n",
    "hapax = [word for word, count in word_counts.items() if count == 1]\n",
    "hapax_pct = (len(hapax) / vocab_size) * 100\n",
    "\n",
    "# Find words appearing 2-5 times\n",
    "rare_2 = [word for word, count in word_counts.items() if count == 2]\n",
    "rare_3_5 = [word for word, count in word_counts.items() if 3 <= count <= 5]\n",
    "rare_le_5 = len(hapax) + len(rare_2) + len(rare_3_5)\n",
    "\n",
    "print(\"RARE WORDS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Hapax legomena (count=1):     {len(hapax):,} words ({hapax_pct:.1f}% of vocab)\")\n",
    "print(f\"Words appearing twice:        {len(rare_2):,} words\")\n",
    "print(f\"Words appearing 3-5 times:    {len(rare_3_5):,} words\")\n",
    "print(f\"\\nTotal rare words (≤5 times):  {rare_le_5:,} words ({(rare_le_5 / vocab_size) * 100:.1f}% of vocab)\")\n",
    "print(f\"\\nExamples of hapax legomena:\")\n",
    "print(f\"  {hapax[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa87cdf99aacf54",
   "metadata": {},
   "source": [
    "A large proportion of the vocabulary in the lyrics is rare: 48.6% are hapax legomena (appearing only once), and 74.3% of all words occur five times or fewer. A few words are repeated frequently, while most words are unique or very infrequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060c92c309c74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_distribution = Counter(word_counts.values())\n",
    "freq_bins = sorted(freq_distribution.keys())[:20]  # First 20 bins\n",
    "freq_counts = [freq_distribution[f] for f in freq_bins]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(freq_bins, freq_counts, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Word Frequency')\n",
    "plt.ylabel('Number of Words')\n",
    "plt.title('Distribution: How Many Words Appear X Times?', fontweight='bold')\n",
    "plt.xticks(freq_bins)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118b3c8df2f687b8",
   "metadata": {},
   "source": [
    "The distribution shows that many words appear only once or very rarely in song lyrics. This is somewhat surprising, as one might expect the opposite: most words occurring very frequently and a few words appearing rarely. However, a closer look at the hapax legomena reveals that these are often words like `['shitforeal', 'denimits', 'matey', 'yohoho', 'yohohoyohoho', 'hahaher', 'swabs', 'bosun', 'yed', 'affydavy']` — not meaningful words in the usual sense, but rather strings or invented terms that mimic sounds made by the singer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5341d40606aff27",
   "metadata": {},
   "source": [
    "## 2.4 Category Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01322eb5e1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df['tag'].unique()\n",
    "\n",
    "category_stats = {}\n",
    "for cat in categories:\n",
    "    cat_df = df[df['tag'] == cat]\n",
    "    cat_text = ' '.join(cat_df['lyrics'].str.lower())\n",
    "    cat_words = cat_text.split()\n",
    "    cat_vocab = len(set(cat_words))\n",
    "\n",
    "    has_number_pct = sum(any(char.isdigit() for char in lyric) for lyric in cat_df['lyrics']) / len(cat_df) * 100\n",
    "\n",
    "    category_stats[cat] = {\n",
    "        'songs': len(cat_df),\n",
    "        'total_words': len(cat_words),\n",
    "        'avg_words': len(cat_words) / len(cat_df),\n",
    "        'vocab': cat_vocab,\n",
    "        'has_number_pct': has_number_pct\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df9e7f9d77d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "avg_words_cat = [category_stats[cat]['avg_words'] for cat in categories]\n",
    "axes[0].bar(categories, avg_words_cat, color='steelblue')\n",
    "axes[0].set_title('Average Words per Song', fontweight='bold')\n",
    "axes[0].set_ylabel('Words')\n",
    "axes[0].set_xticklabels(categories, rotation=45)\n",
    "\n",
    "vocab_sizes = [category_stats[cat]['vocab'] for cat in categories]\n",
    "axes[1].bar(categories, vocab_sizes, color='coral')\n",
    "axes[1].set_title('Vocabulary Size per Genre', fontweight='bold')\n",
    "axes[1].set_ylabel('Unique Words')\n",
    "axes[1].set_xticklabels(categories, rotation=45)\n",
    "\n",
    "has_number_pct = [category_stats[cat]['has_number_pct'] for cat in categories]\n",
    "axes[2].bar(categories, has_number_pct, color='lightgreen')\n",
    "axes[2].set_title('Songs Containing Numbers (%)', fontweight='bold')\n",
    "axes[2].set_ylabel('Percentage')\n",
    "axes[2].set_xticklabels(categories, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28581a1614977250",
   "metadata": {},
   "source": [
    "Rap appears to have a large vocabulary, which aligns with the presence of rare words we observed earlier. Additionally, numbers occur more frequently in rap songs compared to other genres. In contrast, country songs tend to have a very small vocabulary. Across most genres, the average number of words per song is fairly similar, though rap songs are slightly longer, and songs classified as \"Miscellaneous\" (`misc`) are noticeably longer—though this category is not easily interpretable as a specific genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa9c87f8d7a6fc3",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. N-gram Analysis\n",
    "\n",
    "In this chapter, we analyze n-grams — unigrams, bigrams, and trigrams — to explore common word patterns and recurring phrases. The analysis is conducted both across the entire dataset and broken down by artist and genre to uncover stylistic and genre-specific differences.\n",
    "\n",
    "## 3.1 Unigram, Bigram, Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11655666e6475953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(tokens, n):\n",
    "    \"\"\"generate n-grams\"\"\"\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    iters = tee(tokens, n)\n",
    "    for i, it in enumerate(iters):\n",
    "        for _ in range(i):\n",
    "            next(it, None)\n",
    "    return zip(*iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4fe97f1b7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_counts = Counter()\n",
    "bigram_counts = Counter()\n",
    "trigram_counts = Counter()\n",
    "\n",
    "for tokens in df[\"tokens\"]:\n",
    "    unigram_counts.update(tokens)\n",
    "    bigram_counts.update(ngrams(tokens, 2))\n",
    "    trigram_counts.update(ngrams(tokens, 3))\n",
    "\n",
    "top_unigrams = pd.DataFrame(unigram_counts.most_common(15), columns=[\"word\", \"count\"])\n",
    "\n",
    "top_bigrams = pd.DataFrame(\n",
    "    [(\" \".join(k), v) for k, v in bigram_counts.most_common(15)],\n",
    "    columns=[\"bigram\", \"count\"]\n",
    ")\n",
    "top_trigrams = pd.DataFrame(\n",
    "    [(\" \".join(k), v) for k, v in trigram_counts.most_common(15)],\n",
    "    columns=[\"trigram\", \"count\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79150b056987329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOP 15 UNIGRAMS:\")\n",
    "print(\"=\" * 60)\n",
    "print(top_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d35899dead94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOP 15 BIGRAMS:\")\n",
    "print(\"=\" * 60)\n",
    "print(top_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f2bfc9aa5cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOP 15 TRIGRAMS:\")\n",
    "print(\"=\" * 60)\n",
    "print(top_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87361d96931109d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].barh(top_unigrams[\"word\"][::-1], top_unigrams[\"count\"][::-1])\n",
    "axes[0].set_title(\"Top 15 Unigrams\", fontweight='bold')\n",
    "axes[0].set_xlabel(\"Frequency\")\n",
    "\n",
    "axes[1].barh(top_bigrams[\"bigram\"][::-1], top_bigrams[\"count\"][::-1])\n",
    "axes[1].set_title(\"Top 15 Bigrams\", fontweight='bold')\n",
    "axes[1].set_xlabel(\"Frequency\")\n",
    "\n",
    "axes[2].barh(top_trigrams[\"trigram\"][::-1], top_trigrams[\"count\"][::-1])\n",
    "axes[2].set_title(\"Top 15 Trigrams\", fontweight='bold')\n",
    "axes[2].set_xlabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e55d7da105b6607",
   "metadata": {},
   "source": [
    "## 3.2 N-Grams per Artist/Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f068ad44041ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_ngram_for_group(group_df: pd.DataFrame, label_col: str, n: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    returns, for each group (artist/tag), the most frequent n-gram along with its count.\n",
    "    Columns: [label_col, 'ngram', 'count', 'songs']\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for label, sub in group_df.groupby(label_col):\n",
    "        c = Counter()\n",
    "        for toks in sub[\"tokens\"]:\n",
    "            c.update(ngrams(toks, n))\n",
    "        if c:\n",
    "            top_ngram, cnt = c.most_common(1)[0]\n",
    "            rows.append({label_col: label, \"ngram\": \" \".join(top_ngram), \"count\": cnt, \"songs\": len(sub)})\n",
    "        else:\n",
    "            rows.append({label_col: label, \"ngram\": None, \"count\": 0, \"songs\": len(sub)})\n",
    "    return pd.DataFrame(rows).sort_values([label_col]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e1695373d36ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_unigrams_artist = most_common_ngram_for_group(df, \"artist\", n=1).sort_values(\"count\", ascending=False).head(20)\n",
    "top_bigrams_artist  = most_common_ngram_for_group(df, \"artist\", n=2).sort_values(\"count\", ascending=False).head(20)\n",
    "top_trigrams_artist = most_common_ngram_for_group(df, \"artist\", n=3).sort_values(\"count\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f7cebd65c637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "top_unigrams_artist[\"label\"] = top_unigrams_artist[\"artist\"] + \" - \" + top_unigrams_artist[\"ngram\"]\n",
    "top_bigrams_artist[\"label\"]  = top_bigrams_artist[\"artist\"]  + \" - \" + top_bigrams_artist[\"ngram\"]\n",
    "top_trigrams_artist[\"label\"] = top_trigrams_artist[\"artist\"] + \" - \" + top_trigrams_artist[\"ngram\"]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 7))\n",
    "\n",
    "axes[0].barh(top_unigrams_artist[\"label\"][::-1], top_unigrams_artist[\"count\"][::-1])\n",
    "axes[0].set_title(\"Top 20 Unigrams per Artist\", fontweight='bold')\n",
    "axes[0].set_xlabel(\"Frequency\")\n",
    "\n",
    "axes[1].barh(top_bigrams_artist[\"label\"][::-1], top_bigrams_artist[\"count\"][::-1])\n",
    "axes[1].set_title(\"Top 20 Bigrams per Artist\", fontweight='bold')\n",
    "axes[1].set_xlabel(\"Frequency\")\n",
    "\n",
    "axes[2].barh(top_trigrams_artist[\"label\"][::-1], top_trigrams_artist[\"count\"][::-1])\n",
    "axes[2].set_title(\"Top 20 Trigrams per Artist\", fontweight='bold')\n",
    "axes[2].set_xlabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad4d09dafe2f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_unigrams_genre = most_common_ngram_for_group(df, \"tag\", n=1).sort_values(\"count\", ascending=False)\n",
    "top_bigrams_genre  = most_common_ngram_for_group(df, \"tag\", n=2).sort_values(\"count\", ascending=False)\n",
    "top_trigrams_genre = most_common_ngram_for_group(df, \"tag\", n=3).sort_values(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330948947b93f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels\n",
    "top_unigrams_genre[\"label\"] = top_unigrams_genre[\"tag\"] + \" - \" + top_unigrams_genre[\"ngram\"]\n",
    "top_bigrams_genre[\"label\"]  = top_bigrams_genre[\"tag\"]  + \" - \" + top_bigrams_genre[\"ngram\"]\n",
    "top_trigrams_genre[\"label\"] = top_trigrams_genre[\"tag\"] + \" - \" + top_trigrams_genre[\"ngram\"]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].barh(top_unigrams_genre[\"label\"][::-1], top_unigrams_genre[\"count\"][::-1])\n",
    "axes[0].set_title(\"Top Unigrams per Genre\", fontweight='bold')\n",
    "axes[0].set_xlabel(\"Frequency\")\n",
    "\n",
    "axes[1].barh(top_bigrams_genre[\"label\"][::-1], top_bigrams_genre[\"count\"][::-1])\n",
    "axes[1].set_title(\"Top Bigrams per Genre\", fontweight='bold')\n",
    "axes[1].set_xlabel(\"Frequency\")\n",
    "\n",
    "axes[2].barh(top_trigrams_genre[\"label\"][::-1], top_trigrams_genre[\"count\"][::-1])\n",
    "axes[2].set_title(\"Top Trigrams per Genre\", fontweight='bold')\n",
    "axes[2].set_xlabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
