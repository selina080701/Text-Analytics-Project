{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "386dba31b3837c61",
   "metadata": {},
   "source": [
    "# Statistical Analysis: Genius Song Lyrics Subset (1%)\n",
    "\n",
    "**Dataset:** 51'349 Songs | 5'333 Artists | 6 Genres\n",
    "\n",
    "**Purpose:** Explore patterns and distributions in song lyrics across genres and artists. Focus on word frequencies, stylistic differences and similarity structures.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735f3a7ca3023a7",
   "metadata": {},
   "source": [
    "# 1. Dataset Overview\n",
    "## 1.1 Import Packages and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c43beab6da3f3eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:24:56.041557Z",
     "start_time": "2025-10-22T19:24:56.014Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import tee\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b19b53bba2d1f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:03.076748Z",
     "start_time": "2025-10-22T15:49:03.064674Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b626abee835f0c0",
   "metadata": {},
   "source": [
    "## 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872a13cff553462",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:04.191791Z",
     "start_time": "2025-10-22T15:49:03.081770Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean/lyrics_subset_1pct_clean.csv')\n",
    "df = df[df[\"language_cld3\"] == \"en\"] # only english songs, better for analysis\n",
    "\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"Number of Songs: {len(df)} | Artists: {df['artist'].nunique()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d30aa55421d63",
   "metadata": {},
   "source": [
    "## 1.3 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d1b4d6c58b359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:05.361989Z",
     "start_time": "2025-10-22T15:49:05.349813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Genre distribution\n",
    "print(\"\\nGENRE DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "category_counts = df['tag'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "for tag,count in category_counts.items():\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"{tag}: {count:,} songs ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a5a4bea5d6394",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:05.597243Z",
     "start_time": "2025-10-22T15:49:05.449220Z"
    }
   },
   "outputs": [],
   "source": [
    "category_counts.plot(kind=\"bar\")\n",
    "plt.title(\"Genre Distribution\", fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d2971ab1fab64b",
   "metadata": {},
   "source": [
    "# 2. Tokenization\n",
    "## 2.1 Build Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1b84ec956a886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:05.687453Z",
     "start_time": "2025-10-22T15:49:05.680940Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text, lowercase=True):\n",
    "    \"\"\"Clean and tokenize text\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "preprocess_text(\"This is a test!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4f1bcd99b9922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:07.729202Z",
     "start_time": "2025-10-22T15:49:05.725972Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"tokens_raw\"] = df[\"lyrics\"].apply(preprocess_text)\n",
    "df[\"word_count\"] = df[\"tokens_raw\"].apply(len) # words per song\n",
    "\n",
    "df[['title','artist','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e5acb85a6d3ebe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:08.255008Z",
     "start_time": "2025-10-22T15:49:08.247753Z"
    }
   },
   "outputs": [],
   "source": [
    "total_lyrics = len(df)\n",
    "total_words_raw = df[\"word_count\"].sum()\n",
    "avg_words_raw = df[\"word_count\"].mean()\n",
    "min_words_raw = df[\"word_count\"].min()\n",
    "max_words_raw = df[\"word_count\"].max()\n",
    "\n",
    "print(\"TEXT STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total lyrics (songs):     {total_lyrics:,}\")\n",
    "print(f\"Total words:              {total_words_raw:,}\")\n",
    "print(f\"Average words/lyric:      {avg_words_raw:.2f}\")\n",
    "print(f\"Shortest lyric:           {min_words_raw} words\")\n",
    "print(f\"Longest lyric:            {max_words_raw} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb008d0d64e94d3",
   "metadata": {},
   "source": [
    "## 2.2 Filter Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3430f864a4be8bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:08.353179Z",
     "start_time": "2025-10-22T15:49:08.342338Z"
    }
   },
   "outputs": [],
   "source": [
    "STOPWORDS = {\n",
    "    \"the\",\"a\",\"an\",\"and\",\"or\",\"but\",\"if\",\"then\",\"so\",\"than\",\"that\",\"those\",\"these\",\"this\",\n",
    "    \"to\",\"of\",\"in\",\"on\",\"for\",\"with\",\"as\",\"at\",\"by\",\"from\",\"into\",\"over\",\"under\",\"up\",\"down\",\n",
    "    \"is\",\"am\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"do\",\"does\",\"did\",\"doing\",\"have\",\"has\",\"had\",\n",
    "    \"i\",\"you\",\"he\",\"she\",\"it\",\"we\",\"they\",\"me\",\"him\",\"her\",\"us\",\"them\",\"my\",\"your\",\"his\",\"its\",\"our\",\"their\",\n",
    "    \"not\",\"no\",\"yes\",\"yeah\",\"y'all\",\"yall\",\"im\",\"i'm\",\"i’d\",\"i'd\",\"i’ll\",\"i'll\",\"youre\",\"you're\",\"dont\",\"don't\",\n",
    "    \"cant\",\"can't\",\"ill\",\"i’ll\",\"id\",\"i'd\",\"ive\",\"i’ve\",\"ya\",\"oh\",\"ooh\",\"la\",\"na\",\"nah\"\n",
    "}\n",
    "\n",
    "def filtered_tokens(text):\n",
    "    \"\"\"filter stopwords\"\"\"\n",
    "    tokens = preprocess_text(text)\n",
    "    return [t for t in tokens if t not in STOPWORDS and not t.isdigit() and len(t) > 1]\n",
    "\n",
    "filtered_tokens(\"This is a test!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8846b5ef45720f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:11.858579Z",
     "start_time": "2025-10-22T15:49:08.426278Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"lyrics\"].apply(filtered_tokens)\n",
    "tokens_per_row = df[\"tokens\"]\n",
    "tokens = [t for row in tokens_per_row for t in row]\n",
    "df[\"token_count\"] = df[\"tokens\"].apply(len)\n",
    "\n",
    "df[['title','artist','word_count','token_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d878569e14a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:12.534668Z",
     "start_time": "2025-10-22T15:49:12.121576Z"
    }
   },
   "outputs": [],
   "source": [
    "total_lyrics = len(df)\n",
    "total_tokens = len(tokens)\n",
    "unique_tokens = len(set(tokens))\n",
    "avg_tokens = df[\"token_count\"].mean()\n",
    "min_tokens = df[\"token_count\"].min()\n",
    "max_tokens = df[\"token_count\"].max()\n",
    "\n",
    "print(\"TOKEN STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total lyrics (songs):     {total_lyrics:,}\")\n",
    "print(f\"Total tokens:             {total_tokens:,}\")\n",
    "print(f\"Unique tokens:            {unique_tokens:,}\")\n",
    "print(f\"Average tokens/lyric:     {avg_tokens:.2f}\")\n",
    "print(f\"Shortest lyric:           {min_tokens} tokens\")\n",
    "print(f\"Longest lyric:            {max_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee49895f6c0f2dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:15.722093Z",
     "start_time": "2025-10-22T15:49:12.553202Z"
    }
   },
   "outputs": [],
   "source": [
    "top_n = 15\n",
    "tokens_raw = [t for row in df[\"tokens_raw\"] for t in row]\n",
    "tokens_filtered = [t for row in df[\"tokens\"] for t in row]\n",
    "\n",
    "word_counts_raw = Counter(tokens_raw).most_common(top_n)\n",
    "word_counts_filtered = Counter(tokens_filtered).most_common(top_n)\n",
    "\n",
    "df_raw = pd.DataFrame(word_counts_raw, columns=[\"word\", \"count\"])\n",
    "df_filtered = pd.DataFrame(word_counts_filtered, columns=[\"word\", \"count\"])\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "axes[0].bar(df_raw[\"word\"], df_raw[\"count\"])\n",
    "axes[0].set_title(f\"Top {top_n} Words (Before Stopword Removal)\", fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "axes[1].bar(df_filtered[\"word\"], df_filtered[\"count\"])\n",
    "axes[1].set_title(f\"Top {top_n} Words (After Stopword Removal)\", fontsize=12, fontweight='bold')\n",
    "axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f61066d005a5ff",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Word-Level Analysis\n",
    "## 3.1 Vocabulary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6db6743420f42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:17.091596Z",
     "start_time": "2025-10-22T15:49:15.773289Z"
    }
   },
   "outputs": [],
   "source": [
    "# get all words\n",
    "all_tokens = [token for tokens in df[\"tokens_raw\"] for token in tokens]\n",
    "\n",
    "# count unique words\n",
    "word_counts = Counter(all_tokens)\n",
    "vocab_size = len(word_counts)\n",
    "type_token_ratio = vocab_size / len(all_tokens)\n",
    "\n",
    "print(\"VOCABULARY STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total word tokens:          {len(all_tokens):,}\")\n",
    "print(f\"Unique words (vocabulary):  {vocab_size:,}\")\n",
    "print(f\"Type-token ratio:           {type_token_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e33e902a37c8f8b",
   "metadata": {},
   "source": [
    "On average, each word appears roughly 100 times in the dataset, indicating a high level of repetition.\n",
    "\n",
    "The type–token ratio (TTR) of 0.012 is relatively low, which was to be expected since the corpus consists of song lyrics — a genre characterized by recurring words, refrains, and limited lexical variety compared to other types of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06806d883157f95",
   "metadata": {},
   "source": [
    "## 3.2 Zipf's Law Analysis\n",
    "\n",
    "**Zipf's Law:** In natural language, word frequency is inversely proportional to rank.\n",
    "\n",
    "Mathematical form: **f(r) = C / r^α**\n",
    "\n",
    "Where:\n",
    "- f(r) = frequency at rank r\n",
    "- α = slope (ideal = -1.0 for natural language)\n",
    "- C = coefficient\n",
    "\n",
    "If α = -1.0, then rank 2 word appears half as often as rank 1, rank 3 appears 1/3 as often, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfcf78250f3595b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:18.429801Z",
     "start_time": "2025-10-22T15:49:17.319738Z"
    }
   },
   "outputs": [],
   "source": [
    "all_word_freq = Counter(tokens_raw).most_common(100)\n",
    "ranks = list(range(1, len(all_word_freq) + 1))\n",
    "frequencies = [freq for word, freq in all_word_freq]\n",
    "\n",
    "# Fit power law model (top 100 words)\n",
    "log_ranks_100 = np.log(ranks).reshape(-1, 1)\n",
    "log_freq_100 = np.log(frequencies)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(log_ranks_100, log_freq_100)\n",
    "\n",
    "r_squared = model.score(log_ranks_100, log_freq_100)\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "coefficient_C = np.exp(intercept)\n",
    "\n",
    "print(\"ZIPF'S LAW ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Fitted equation: f(r) = {coefficient_C:.2f} / r^{abs(slope):.3f}\")\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Slope (α):         {slope:.4f}\")\n",
    "print(f\"  R^2 (fit quality): {r_squared:.4f}\")\n",
    "print(f\"  Ideal Zipf slope:  -1.0000\")\n",
    "print(f\"  Deviation:         {abs(slope + 1.0):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e778e724e6192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:19.756874Z",
     "start_time": "2025-10-22T15:49:18.620732Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Log-log plot\n",
    "axes[0].loglog(ranks, frequencies, 'o', alpha=0.7, color='steelblue', label='Actual')\n",
    "fitted_zipf = [coefficient_C / (r ** abs(slope)) for r in ranks]\n",
    "axes[0].loglog(ranks, fitted_zipf, 'g-', linewidth=2, alpha=0.8, label=f'Fitted (α={abs(slope):.3f})')\n",
    "ideal_zipf = [frequencies[0] / r for r in ranks]\n",
    "axes[0].loglog(ranks, ideal_zipf, 'r--', linewidth=2, alpha=0.7, label='Ideal Zipf (α=1.0)')\n",
    "axes[0].set_xlabel('Rank (log scale)')\n",
    "axes[0].set_ylabel('Frequency (log scale)')\n",
    "axes[0].set_title(\"Zipf's Law: Actual vs Fitted vs Ideal\", fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Top 30 comparison\n",
    "n = 30\n",
    "axes[1].plot(ranks[:n], frequencies[:n], 'o', color='steelblue', label='Actual')\n",
    "axes[1].plot(ranks[:n], [coefficient_C / (r ** abs(slope)) for r in ranks[:n]],\n",
    "             'g-', label=f'Fitted (α={abs(slope):.3f})', linewidth=2, alpha=0.7)\n",
    "axes[1].plot(ranks[:n], [frequencies[0] / r for r in ranks[:n]],\n",
    "             'r--', label='Ideal Zipf (a=1.0)', linewidth=2, alpha=0.6)\n",
    "axes[1].set_xlabel('Rank')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Top 30 Words: Detailed Comparison', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d82bc7d4c61d45",
   "metadata": {},
   "source": [
    "The fitted Zipf’s Law model shows a slope of −0.83 with an $R^2$ of 0.98, indicating an excellent fit to the expected distribution.\n",
    "\n",
    "Although the slope is slightly flatter than the ideal −1.0, this small deviation (0.17) suggests that the frequency–rank relationship in the lyrics follows Zipf’s Law closely — common words are used much more frequently than rare ones, as typically observed in song lyrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69f557d036935",
   "metadata": {},
   "source": [
    "## 3.3 Hapax Legomena (Rare Words)\n",
    "\n",
    "**Hapax legomena** = words appearing only once in the corpus\n",
    "\n",
    "These are the rarest words. High hapax count suggests diverse vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee8f23e44d04d7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:21.132845Z",
     "start_time": "2025-10-22T15:49:19.975166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find hapax legomena\n",
    "word_counts = Counter(tokens_raw)\n",
    "hapax = [word for word, count in word_counts.items() if count == 1]\n",
    "hapax_pct = (len(hapax) / vocab_size) * 100\n",
    "\n",
    "# Find words appearing 2-5 times\n",
    "rare_2 = [word for word, count in word_counts.items() if count == 2]\n",
    "rare_3_5 = [word for word, count in word_counts.items() if 3 <= count <= 5]\n",
    "rare_le_5 = len(hapax) + len(rare_2) + len(rare_3_5)\n",
    "\n",
    "print(\"RARE WORDS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Hapax legomena (count=1):     {len(hapax):,} words ({hapax_pct:.1f}% of vocab)\")\n",
    "print(f\"Words appearing twice:        {len(rare_2):,} words\")\n",
    "print(f\"Words appearing 3-5 times:    {len(rare_3_5):,} words\")\n",
    "print(f\"\\nTotal rare words (≤5 times):  {rare_le_5:,} words ({(rare_le_5 / vocab_size) * 100:.1f}% of vocab)\")\n",
    "print(f\"\\nExamples of hapax legomena:\")\n",
    "print(f\"  {hapax[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa87cdf99aacf54",
   "metadata": {},
   "source": [
    "A large proportion of the vocabulary in the lyrics is rare: 48.6% are hapax legomena (appearing only once), and 74.3% of all words occur five times or fewer. A few words are repeated frequently, while most words are unique or very infrequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060c92c309c74ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:21.503666Z",
     "start_time": "2025-10-22T15:49:21.362111Z"
    }
   },
   "outputs": [],
   "source": [
    "freq_distribution = Counter(word_counts.values())\n",
    "freq_bins = sorted(freq_distribution.keys())[:20]  # First 20 bins\n",
    "freq_counts = [freq_distribution[f] for f in freq_bins]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(freq_bins, freq_counts, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Word Frequency')\n",
    "plt.ylabel('Number of Words')\n",
    "plt.title('Distribution: How Many Words Appear X Times?', fontweight='bold')\n",
    "plt.xticks(freq_bins)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5341d40606aff27",
   "metadata": {},
   "source": [
    "## 3.4 Category Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01322eb5e1d7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:25.198801Z",
     "start_time": "2025-10-22T15:49:21.511943Z"
    }
   },
   "outputs": [],
   "source": [
    "categories = df['tag'].unique()\n",
    "\n",
    "category_stats = {}\n",
    "for cat in categories:\n",
    "    cat_df = df[df['tag'] == cat]\n",
    "    cat_text = ' '.join(cat_df['lyrics'].str.lower())\n",
    "    cat_words = cat_text.split()\n",
    "    cat_vocab = len(set(cat_words))\n",
    "\n",
    "    has_number_pct = sum(any(char.isdigit() for char in lyric) for lyric in cat_df['lyrics']) / len(cat_df) * 100\n",
    "\n",
    "    category_stats[cat] = {\n",
    "        'songs': len(cat_df),\n",
    "        'total_words': len(cat_words),\n",
    "        'avg_words': len(cat_words) / len(cat_df),\n",
    "        'vocab': cat_vocab,\n",
    "        'has_number_pct': has_number_pct\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df9e7f9d77d181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:25.739114Z",
     "start_time": "2025-10-22T15:49:25.428175Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "avg_words_cat = [category_stats[cat]['avg_words'] for cat in categories]\n",
    "axes[0].bar(categories, avg_words_cat, color='steelblue')\n",
    "axes[0].set_title('Average Words per Song', fontweight='bold')\n",
    "axes[0].set_ylabel('Words')\n",
    "axes[0].set_xticklabels(categories, rotation=45)\n",
    "\n",
    "vocab_sizes = [category_stats[cat]['vocab'] for cat in categories]\n",
    "axes[1].bar(categories, vocab_sizes, color='coral')\n",
    "axes[1].set_title('Vocabulary Size per Genre', fontweight='bold')\n",
    "axes[1].set_ylabel('Unique Words')\n",
    "axes[1].set_xticklabels(categories, rotation=45)\n",
    "\n",
    "has_number_pct = [category_stats[cat]['has_number_pct'] for cat in categories]\n",
    "axes[2].bar(categories, has_number_pct, color='lightgreen')\n",
    "axes[2].set_title('Songs Containing Numbers (%)', fontweight='bold')\n",
    "axes[2].set_ylabel('Percentage')\n",
    "axes[2].set_xticklabels(categories, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa9c87f8d7a6fc3",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. N-gram Analysis\n",
    "## 4.1 Unigram, Bigram, Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11655666e6475953",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:25.761921Z",
     "start_time": "2025-10-22T15:49:25.756371Z"
    }
   },
   "outputs": [],
   "source": [
    "def ngrams(tokens, n):\n",
    "    \"\"\"generate n-grams\"\"\"\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    iters = tee(tokens, n)\n",
    "    for i, it in enumerate(iters):\n",
    "        for _ in range(i):\n",
    "            next(it, None)\n",
    "    return zip(*iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4fe97f1b7519",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:33.334641Z",
     "start_time": "2025-10-22T15:49:25.769448Z"
    }
   },
   "outputs": [],
   "source": [
    "unigram_counts = Counter()\n",
    "bigram_counts = Counter()\n",
    "trigram_counts = Counter()\n",
    "\n",
    "for tokens in df[\"tokens\"]:\n",
    "    unigram_counts.update(tokens)\n",
    "    bigram_counts.update(ngrams(tokens, 2))\n",
    "    trigram_counts.update(ngrams(tokens, 3))\n",
    "\n",
    "top_unigrams = pd.DataFrame(unigram_counts.most_common(15), columns=[\"word\", \"count\"])\n",
    "\n",
    "top_bigrams = pd.DataFrame(\n",
    "    [(\" \".join(k), v) for k, v in bigram_counts.most_common(15)],\n",
    "    columns=[\"bigram\", \"count\"]\n",
    ")\n",
    "top_trigrams = pd.DataFrame(\n",
    "    [(\" \".join(k), v) for k, v in trigram_counts.most_common(15)],\n",
    "    columns=[\"trigram\", \"count\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79150b056987329b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:46.637838Z",
     "start_time": "2025-10-22T15:49:46.633531Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"TOP 15 UNIGRAMS:\")\n",
    "print(\"=\" * 60)\n",
    "print(top_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d35899dead94c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:46.656621Z",
     "start_time": "2025-10-22T15:49:46.652100Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"TOP 15 BIGRAMS:\")\n",
    "print(\"=\" * 60)\n",
    "print(top_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f2bfc9aa5cd3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:46.676140Z",
     "start_time": "2025-10-22T15:49:46.671210Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"TOP 15 TRIGRAMS:\")\n",
    "print(\"=\" * 60)\n",
    "print(top_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87361d96931109d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:47.020528Z",
     "start_time": "2025-10-22T15:49:46.683667Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].barh(top_unigrams[\"word\"][::-1], top_unigrams[\"count\"][::-1])\n",
    "axes[0].set_title(\"Top 15 Unigrams\", fontweight='bold')\n",
    "axes[0].set_xlabel(\"Frequency\")\n",
    "\n",
    "axes[1].barh(top_bigrams[\"bigram\"][::-1], top_bigrams[\"count\"][::-1])\n",
    "axes[1].set_title(\"Top 15 Bigrams\", fontweight='bold')\n",
    "axes[1].set_xlabel(\"Frequency\")\n",
    "\n",
    "axes[2].barh(top_trigrams[\"trigram\"][::-1], top_trigrams[\"count\"][::-1])\n",
    "axes[2].set_title(\"Top 15 Trigrams\", fontweight='bold')\n",
    "axes[2].set_xlabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e55d7da105b6607",
   "metadata": {},
   "source": [
    "## 4.2 N-Grams per Artist/Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f068ad44041ece3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:47.033577Z",
     "start_time": "2025-10-22T15:49:47.028052Z"
    }
   },
   "outputs": [],
   "source": [
    "def most_common_ngram_for_group(group_df: pd.DataFrame, label_col: str, n: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    returns, for each group (artist/tag), the most frequent n-gram along with its count.\n",
    "    Columns: [label_col, 'ngram', 'count', 'songs']\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for label, sub in group_df.groupby(label_col):\n",
    "        c = Counter()\n",
    "        for toks in sub[\"tokens\"]:\n",
    "            c.update(ngrams(toks, n))\n",
    "        if c:\n",
    "            top_ngram, cnt = c.most_common(1)[0]\n",
    "            rows.append({label_col: label, \"ngram\": \" \".join(top_ngram), \"count\": cnt, \"songs\": len(sub)})\n",
    "        else:\n",
    "            rows.append({label_col: label, \"ngram\": None, \"count\": 0, \"songs\": len(sub)})\n",
    "    return pd.DataFrame(rows).sort_values([label_col]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e1695373d36ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:49:53.690027Z",
     "start_time": "2025-10-22T15:49:47.041692Z"
    }
   },
   "outputs": [],
   "source": [
    "top_unigrams_artist = most_common_ngram_for_group(df, \"artist\", n=1).sort_values(\"count\", ascending=False).head(20)\n",
    "top_bigrams_artist  = most_common_ngram_for_group(df, \"artist\", n=2).sort_values(\"count\", ascending=False).head(20)\n",
    "top_trigrams_artist = most_common_ngram_for_group(df, \"artist\", n=3).sort_values(\"count\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f7cebd65c637c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:50:06.726128Z",
     "start_time": "2025-10-22T15:50:06.253057Z"
    }
   },
   "outputs": [],
   "source": [
    "# create labels\n",
    "top_unigrams_artist[\"label\"] = top_unigrams_artist[\"artist\"] + \" - \" + top_unigrams_artist[\"ngram\"]\n",
    "top_bigrams_artist[\"label\"]  = top_bigrams_artist[\"artist\"]  + \" - \" + top_bigrams_artist[\"ngram\"]\n",
    "top_trigrams_artist[\"label\"] = top_trigrams_artist[\"artist\"] + \" - \" + top_trigrams_artist[\"ngram\"]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 7))\n",
    "\n",
    "axes[0].barh(top_unigrams_artist[\"label\"][::-1], top_unigrams_artist[\"count\"][::-1])\n",
    "axes[0].set_title(\"Top 20 Unigrams per Artist\", fontweight='bold')\n",
    "axes[0].set_xlabel(\"Frequency\")\n",
    "\n",
    "axes[1].barh(top_bigrams_artist[\"label\"][::-1], top_bigrams_artist[\"count\"][::-1])\n",
    "axes[1].set_title(\"Top 20 Bigrams per Artist\", fontweight='bold')\n",
    "axes[1].set_xlabel(\"Frequency\")\n",
    "\n",
    "axes[2].barh(top_trigrams_artist[\"label\"][::-1], top_trigrams_artist[\"count\"][::-1])\n",
    "axes[2].set_title(\"Top 20 Trigrams per Artist\", fontweight='bold')\n",
    "axes[2].set_xlabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad4d09dafe2f6d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:50:12.974113Z",
     "start_time": "2025-10-22T15:50:06.735837Z"
    }
   },
   "outputs": [],
   "source": [
    "top_unigrams_genre = most_common_ngram_for_group(df, \"tag\", n=1).sort_values(\"count\", ascending=False)\n",
    "top_bigrams_genre  = most_common_ngram_for_group(df, \"tag\", n=2).sort_values(\"count\", ascending=False)\n",
    "top_trigrams_genre = most_common_ngram_for_group(df, \"tag\", n=3).sort_values(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330948947b93f6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T15:50:26.914804Z",
     "start_time": "2025-10-22T15:50:25.954411Z"
    }
   },
   "outputs": [],
   "source": [
    "# create labels\n",
    "top_unigrams_genre[\"label\"] = top_unigrams_genre[\"tag\"] + \" - \" + top_unigrams_genre[\"ngram\"]\n",
    "top_bigrams_genre[\"label\"]  = top_bigrams_genre[\"tag\"]  + \" - \" + top_bigrams_genre[\"ngram\"]\n",
    "top_trigrams_genre[\"label\"] = top_trigrams_genre[\"tag\"] + \" - \" + top_trigrams_genre[\"ngram\"]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].barh(top_unigrams_genre[\"label\"][::-1], top_unigrams_genre[\"count\"][::-1])\n",
    "axes[0].set_title(\"Top Unigrams per Genre\", fontweight='bold')\n",
    "axes[0].set_xlabel(\"Frequency\")\n",
    "\n",
    "axes[1].barh(top_bigrams_genre[\"label\"][::-1], top_bigrams_genre[\"count\"][::-1])\n",
    "axes[1].set_title(\"Top Bigrams per Genre\", fontweight='bold')\n",
    "axes[1].set_xlabel(\"Frequency\")\n",
    "\n",
    "axes[2].barh(top_trigrams_genre[\"label\"][::-1], top_trigrams_genre[\"count\"][::-1])\n",
    "axes[2].set_title(\"Top Trigrams per Genre\", fontweight='bold')\n",
    "axes[2].set_xlabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf3f9af8fd8bee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:14:30.516940Z",
     "start_time": "2025-10-22T19:14:30.117054Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4ef0149efe2ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:28:28.341230Z",
     "start_time": "2025-10-22T19:28:16.800215Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = \"data/clean\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(output_dir, \"data.csv\")\n",
    "\n",
    "df = df.rename(columns={'tokens_raw': 'words'})\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Cleaned Subset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85176c5c881110f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
