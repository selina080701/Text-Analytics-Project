{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd7f1364df4739",
   "metadata": {},
   "source": [
    "# Tokenization: Genius Song Lyrics Subset (1%)\n",
    "\n",
    "**Dataset:** 51'349 Songs | 5'333 Artists | 6 Genres\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc14bffb62e0547",
   "metadata": {},
   "source": [
    "# 1. Dataset Overview\n",
    "## 1.1 Import Packages and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T17:06:49.169450Z",
     "start_time": "2025-10-23T17:06:49.151354Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import tee\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc58bbdc538f8c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T17:06:49.225132Z",
     "start_time": "2025-10-23T17:06:49.212411Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b037bfd5f24edd",
   "metadata": {},
   "source": [
    "## 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76769074a5c09e7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T17:06:51.831434Z",
     "start_time": "2025-10-23T17:06:49.244021Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean/lyrics_subset_1pct_clean.csv')\n",
    "df = df[df[\"language_cld3\"] == \"en\"] # only english songs, better for analysis\n",
    "\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"Number of Songs: {len(df)} | Artists: {df['artist'].nunique()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8385b47d061977e5",
   "metadata": {},
   "source": [
    "# 2. Tokenization\n",
    "## 2.1 Build Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742fd69932e07e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T17:06:51.926182Z",
     "start_time": "2025-10-23T17:06:51.919292Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text, lowercase=True):\n",
    "    \"\"\"Clean and tokenize text\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "preprocess_text(\"This is a test!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2aa26a6e69b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T17:06:56.312504Z",
     "start_time": "2025-10-23T17:06:53.983043Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"words\"] = df[\"lyrics\"].apply(preprocess_text)\n",
    "df[\"word_count\"] = df[\"words\"].apply(len) # words per song\n",
    "\n",
    "df[['title','artist','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97900a336f699d55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T17:06:56.400833Z",
     "start_time": "2025-10-23T17:06:56.392049Z"
    }
   },
   "outputs": [],
   "source": [
    "total_lyrics = len(df)\n",
    "total_words_raw = df[\"word_count\"].sum()\n",
    "avg_words_raw = df[\"word_count\"].mean()\n",
    "min_words_raw = df[\"word_count\"].min()\n",
    "max_words_raw = df[\"word_count\"].max()\n",
    "\n",
    "print(\"TEXT STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total lyrics (songs):     {total_lyrics:,}\")\n",
    "print(f\"Total words:              {total_words_raw:,}\")\n",
    "print(f\"Average words/lyric:      {avg_words_raw:.2f}\")\n",
    "print(f\"Shortest lyric:           {min_words_raw} words\")\n",
    "print(f\"Longest lyric:            {max_words_raw} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99bdfa045f04b83",
   "metadata": {},
   "source": [
    "## 2.2 Filter Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df510b0aa1ee1577",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "STOPWORDS = {\n",
    "    \"the\",\"a\",\"an\",\"and\",\"or\",\"but\",\"if\",\"then\",\"so\",\"than\",\"that\",\"those\",\"these\",\"this\",\n",
    "    \"to\",\"of\",\"in\",\"on\",\"for\",\"with\",\"as\",\"at\",\"by\",\"from\",\"into\",\"over\",\"under\",\"up\",\"down\",\n",
    "    \"is\",\"am\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"do\",\"does\",\"did\",\"doing\",\"have\",\"has\",\"had\",\n",
    "    \"i\",\"you\",\"he\",\"she\",\"it\",\"we\",\"they\",\"me\",\"him\",\"her\",\"us\",\"them\",\"my\",\"your\",\"his\",\"its\",\"our\",\"their\",\n",
    "    \"not\",\"no\",\"yes\",\"yeah\",\"y'all\",\"yall\",\"im\",\"i'm\",\"i’d\",\"i'd\",\"i’ll\",\"i'll\",\"youre\",\"you're\",\"dont\",\"don't\",\n",
    "    \"cant\",\"can't\",\"ill\",\"i’ll\",\"id\",\"i'd\",\"ive\",\"i’ve\",\"ya\",\"oh\",\"ooh\",\"la\",\"na\",\"nah\"\n",
    "}\n",
    "\n",
    "def filtered_tokens(text):\n",
    "    \"\"\"filter stopwords\"\"\"\n",
    "    tokens = preprocess_text(text)\n",
    "    return [t for t in tokens if t not in STOPWORDS and not t.isdigit() and len(t) > 1]\n",
    "\n",
    "filtered_tokens(\"This is a test!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b9e639b344d2d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T16:48:48.369593Z",
     "start_time": "2025-10-23T16:48:45.454584Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"lyrics\"].apply(filtered_tokens)\n",
    "tokens_per_row = df[\"tokens\"]\n",
    "tokens = [t for row in tokens_per_row for t in row]\n",
    "df[\"token_count\"] = df[\"tokens\"].apply(len)\n",
    "\n",
    "df[['title','artist','word_count','tokens','token_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917fc872485bdce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T16:48:48.965267Z",
     "start_time": "2025-10-23T16:48:48.614062Z"
    }
   },
   "outputs": [],
   "source": [
    "total_lyrics = len(df)\n",
    "total_tokens = len(tokens)\n",
    "unique_tokens = len(set(tokens))\n",
    "avg_tokens = df[\"token_count\"].mean()\n",
    "min_tokens = df[\"token_count\"].min()\n",
    "max_tokens = df[\"token_count\"].max()\n",
    "\n",
    "print(\"TOKEN STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total lyrics (songs):     {total_lyrics:,}\")\n",
    "print(f\"Total tokens:             {total_tokens:,}\")\n",
    "print(f\"Unique tokens:            {unique_tokens:,}\")\n",
    "print(f\"Average tokens/lyric:     {avg_tokens:.2f}\")\n",
    "print(f\"Shortest lyric:           {min_tokens} tokens\")\n",
    "print(f\"Longest lyric:            {max_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d8a5cd824cc2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T16:48:52.139890Z",
     "start_time": "2025-10-23T16:48:49.026894Z"
    }
   },
   "outputs": [],
   "source": [
    "top_n = 15\n",
    "words = [t for row in df[\"words\"] for t in row]\n",
    "tokens_filtered = [t for row in df[\"tokens\"] for t in row]\n",
    "\n",
    "word_counts_raw = Counter(words).most_common(top_n)\n",
    "word_counts_filtered = Counter(tokens_filtered).most_common(top_n)\n",
    "\n",
    "df_raw = pd.DataFrame(word_counts_raw, columns=[\"word\", \"count\"])\n",
    "df_filtered = pd.DataFrame(word_counts_filtered, columns=[\"word\", \"count\"])\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "axes[0].bar(df_raw[\"word\"], df_raw[\"count\"])\n",
    "axes[0].set_title(f\"Top {top_n} Words (Before Stopword Removal)\", fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "axes[1].bar(df_filtered[\"word\"], df_filtered[\"count\"])\n",
    "axes[1].set_title(f\"Top {top_n} Words (After Stopword Removal)\", fontsize=12, fontweight='bold')\n",
    "axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adc93f1ca0febaa",
   "metadata": {},
   "source": [
    "# 3. Save final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0551d7da5f38af8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T16:48:52.186312Z",
     "start_time": "2025-10-23T16:48:52.176548Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a19c136c41eb5ff",
   "metadata": {},
   "source": [
    "## 3.1 Configuration\n",
    "\n",
    "* Define output directory and file name.\n",
    "* Create directory if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de08e4603233ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T16:48:52.282608Z",
     "start_time": "2025-10-23T16:48:52.279183Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = \"data/clean\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(output_dir, \"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d12a30fcc41dab",
   "metadata": {},
   "source": [
    "# 3.2 Save Dataset locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908c5c3bbaaa1f8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T16:48:59.210458Z",
     "start_time": "2025-10-23T16:48:52.353289Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Cleaned Subset saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
