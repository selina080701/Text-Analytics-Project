{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e91810475fe9505",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Word Embedding\n",
    "## 5.1 Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79da3c647aeb2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:43:07.929507Z",
     "start_time": "2025-10-22T19:43:07.924230Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.graph_objects as go\n",
    "import ast\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731abc1a3865674b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:50:44.016668Z",
     "start_time": "2025-10-22T19:43:08.356433Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"data/clean/data.csv\")\n",
    "\n",
    "# nur englische Zeilen behalten\n",
    "df = df[df[\"language_cld3\"] == \"en\"]\n",
    "\n",
    "if isinstance(df[\"tokens\"].iloc[0], str):\n",
    "    df[\"tokens\"] = df[\"tokens\"].apply(ast.literal_eval)\n",
    "\n",
    "sentences = df[\"tokens\"].dropna().tolist()\n",
    "\n",
    "# Word2Vec trainieren\n",
    "model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=50,\n",
    "    window=5,         # KontextfenstergrÃ¶ÃŸe\n",
    "    min_count=2,      # ignoriert seltene WÃ¶rter\n",
    "    workers=4,        # parallele Threads\n",
    "    epochs=100         # TrainingsdurchlÃ¤ufe\n",
    ")\n",
    "\n",
    "# Ergebnisse prÃ¼fen\n",
    "print(\"Model trained!\")\n",
    "print(\"Vocabulary size:\", len(model.wv))\n",
    "print(\"Vector size:\", model.wv.vector_size)\n",
    "\n",
    "# Beispielverwendung\n",
    "word = \"love\"\n",
    "if word in model.wv:\n",
    "    print(f\"\\nVector for '{word}':\", model.wv[word][:10])\n",
    "    print(\"\\nMost similar words to 'love':\")\n",
    "    print(model.wv.most_similar(word, topn=5))\n",
    "else:\n",
    "    print(f\"'{word}' not in vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0bc32c616b695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:53:53.370457Z",
     "start_time": "2025-10-22T19:53:53.356363Z"
    }
   },
   "outputs": [],
   "source": [
    "# Beispiel: Ã¤hnliche WÃ¶rter finden\n",
    "test_word = \"love\"\n",
    "if test_word in model.wv:\n",
    "    print(f\"\\nMost similar to '{test_word}':\")\n",
    "    for w, s in model.wv.most_similar(test_word, topn=5):\n",
    "        print(f\"  {w:15s} {s:.3f}\")\n",
    "else:\n",
    "    print(f\"'{test_word}' not in vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13acb9723a74b2c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:54:50.737137Z",
     "start_time": "2025-10-22T19:54:50.315154Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_similar_words(word, model, top_n=5):\n",
    "    if word not in model.wv:\n",
    "        return None, None\n",
    "\n",
    "    similar = model.wv.most_similar(word, topn=top_n)\n",
    "\n",
    "    words = [w for w, _ in similar]\n",
    "    scores = [s for _, s in similar]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 3))\n",
    "    ax.barh(words, scores)\n",
    "    ax.set_xlabel(\"Similarity\")\n",
    "    ax.set_title(f\"Words similar to '{word}'\")\n",
    "    ax.invert_yaxis()  # top = most similar\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return similar, fig\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "test_words = [\"skinny\", \"love\", \"happy\"]\n",
    "\n",
    "for word in test_words:\n",
    "    print(f\"\\nðŸ” Finding words similar to '{word}'...\")\n",
    "    similar, fig = find_similar_words(word, model, top_n=5)\n",
    "\n",
    "    if similar:\n",
    "        print(\"Results:\")\n",
    "        for sim_word, score in similar:\n",
    "            bar = 'â–ˆ' * int(score * 10)\n",
    "            print(f\"  {sim_word:10} {bar} {score:.2f}\")\n",
    "        if fig:\n",
    "            plt.show()   # display the bar chart\n",
    "    else:\n",
    "        print(f\"  '{word}' not in vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bbda94da9509b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:56:53.204980Z",
     "start_time": "2025-10-22T19:56:53.146422Z"
    }
   },
   "outputs": [],
   "source": [
    "def explore_embedding_space(model, n_words=30):\n",
    "    vocab = list(model.wv.index_to_key)\n",
    "    if len(vocab) == 0:\n",
    "        raise ValueError(\"The model has an empty vocabulary.\")\n",
    "    n = min(n_words, len(vocab))\n",
    "    words = vocab[:n]\n",
    "\n",
    "    vectors = np.array([model.wv[w] for w in words])\n",
    "\n",
    "    if vectors.shape[1] > 3:\n",
    "        pca = PCA(n_components=3)\n",
    "        vectors_3d = pca.fit_transform(vectors)\n",
    "        axis_titles = (\"PC1\", \"PC2\", \"PC3\")\n",
    "    else:\n",
    "        vectors_3d = vectors\n",
    "        axis_titles = tuple(f\"Dim{i+1}\" for i in range(vectors.shape[1]))\n",
    "\n",
    "    distances = np.linalg.norm(vectors_3d, axis=1)\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "                x=vectors_3d[:, 0],\n",
    "                y=vectors_3d[:, 1] if vectors_3d.shape[1] > 1 else np.zeros_like(distances),\n",
    "                z=vectors_3d[:, 2] if vectors_3d.shape[1] > 2 else np.zeros_like(distances),\n",
    "                mode=\"markers+text\",\n",
    "                text=words,\n",
    "                textposition=\"top center\",\n",
    "                marker=dict(\n",
    "                    size=np.clip(distances * 3, 4, 24),\n",
    "                    color=distances,\n",
    "                    colorscale=\"Viridis\",\n",
    "                    showscale=True,\n",
    "                    colorbar=dict(title=\"Distance\"),\n",
    "                ),\n",
    "                hovertemplate=\"<b>%{text}</b><br>Distance: %{marker.color:.2f}<extra></extra>\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Explore the Word Space (Top {n} words) â€” Size/Color = Distance from Origin\",\n",
    "        scene=dict(\n",
    "            xaxis_title=axis_titles[0],\n",
    "            yaxis_title=axis_titles[1] if len(axis_titles) > 1 else \"\",\n",
    "            zaxis_title=axis_titles[2] if len(axis_titles) > 2 else \"\",\n",
    "        ),\n",
    "        height=600,\n",
    "        margin=dict(l=0, r=0, t=40, b=0),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "fig = explore_embedding_space(model, n_words=100)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5fc800baa29a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
