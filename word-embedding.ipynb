{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e91810475fe9505",
   "metadata": {},
   "source": [
    "# Word Embedding: Genius Song Lyrics Subset (1%)\n",
    "\n",
    "**Purpose:** Create and explore word embeddings.\n",
    "**Details:** Uses tokenized data to generate embeddings, visualize semantic relationships, and analyze similarity between words.\n",
    "\n",
    "---"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Train Model\n",
    "## 1.1 Load and prepare Data"
   ],
   "id": "be672a521c382ca8"
  },
  {
   "cell_type": "code",
   "id": "af79da3c647aeb2e",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.graph_objects as go\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import plotly.express as px\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Relevante Spalten:**\n",
    "- `language_cld3` ‚Äî erkannte Sprache (typisch ISO-Code, z. B. `en` f√ºr Englisch)\n",
    "- `tokens` ‚Äî Liste der Token (W√∂rter) der Lyrics pro Zeile\n",
    "\n",
    "**Hinweis:** F√ºr Word2Vec m√ºssen es **Listen von Strings** sein."
   ],
   "id": "6abb782a5ed108d1"
  },
  {
   "cell_type": "code",
   "id": "2660e870a9feffb0",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"data/clean/data.csv\")\n",
    "\n",
    "df = df[df[\"language_cld3\"] == \"en\"]\n",
    "\n",
    "if isinstance(df[\"tokens\"].iloc[0], str):\n",
    "    df[\"tokens\"] = df[\"tokens\"].apply(ast.literal_eval)\n",
    "\n",
    "sentences = df[\"tokens\"].dropna().tolist()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.2 Train Word2Vec Model\n",
    "\n",
    "**Ziel:** Lernen von Wortvektoren aus den Lyrics-Token.\n",
    "**Bibliothek:** `gensim.models.Word2Vec`\n",
    "\n",
    "### Wichtige Parameter\n",
    "\n",
    "| Parameter     | Bedeutung |\n",
    "|----------------|------------|\n",
    "| `sentences`    | Eingabedaten als Liste von Wortlisten (siehe Schritt 1) |\n",
    "| `vector_size=50` | Dimension der Wortvektoren (kompakte Darstellung, schnelleres Training; ausreichend f√ºr einen ersten Durchlauf) |\n",
    "| `window=5`     | Kontextfenster: betrachtet bis zu 5 W√∂rter **links und rechts** eines Zielworts ‚Üí balanciert lokalen und mittleren Kontext |\n",
    "| `min_count=2`  | Ignoriert seltene W√∂rter (< 2 Vorkommen) ‚Üí reduziert Rauschen & Vokabulargr√∂√üe |\n",
    "| `workers=4`    | Nutzt 4 Threads zur Parallelisierung ‚Üí schnelleres Training (abh√§ngig von CPU) |\n",
    "| `epochs=100`   | 100 Epochen (vollst√§ndige Durchl√§ufe √ºber die Daten) ‚Üí stabilere Vektoren bei kleineren Datens√§tzen |\n"
   ],
   "id": "adf8fa3ad051e1d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=50,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    epochs=100\n",
    ")\n",
    "\n",
    "print(\"Model trained!\")\n",
    "print(\"Vocabulary size:\", len(model.wv))\n",
    "print(\"Vector size:\", model.wv.vector_size)"
   ],
   "id": "5971ce71a3774720",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Ergebnis:** Ein trainiertes Word2Vec-Modell, das semantische Beziehungen zwischen W√∂rtern\n",
    "in einem 50-dimensionalen Raum abbildet.\n",
    "\n",
    "**Beispiele:** √Ñhnlichkeiten zwischen W√∂rtern (`model.wv.most_similar(\"love\")`)"
   ],
   "id": "318be596d4bda9bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Explore Embedding Space\n",
    "## 2.1 Embedding Examples: 'love'"
   ],
   "id": "4defa97d4d5928e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "word = \"love\"\n",
    "if word in model.wv:\n",
    "    print(f\"\\nVector for '{word}':\", model.wv[word][:10])\n",
    "    print(\"\\nMost similar words to 'love':\")\n",
    "    print(model.wv.most_similar(word, topn=5))\n",
    "else:\n",
    "    print(f\"'{word}' not in vocabulary.\")"
   ],
   "id": "731abc1a3865674b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13acb9723a74b2c2",
   "metadata": {},
   "source": [
    "def find_similar_words(word, model, top_n=5):\n",
    "    if word not in model.wv:\n",
    "        return None, None\n",
    "    similar = model.wv.most_similar(word, topn=top_n)\n",
    "    words = [w for w, _ in similar]\n",
    "    scores = [s for _, s in similar]\n",
    "    return words, scores\n",
    "\n",
    "\n",
    "test_words = [\"baby\", \"love\", \"happy\"]\n",
    "\n",
    "# Store results for plotting in next cell\n",
    "similar_results = {}\n",
    "\n",
    "for word in test_words:\n",
    "    print(f\"\\nüîç Finding words similar to '{word}'...\")\n",
    "    words, scores = find_similar_words(word, model, top_n=5)\n",
    "\n",
    "    if words:\n",
    "        similar_results[word] = (words, scores)\n",
    "\n",
    "        for w, s in zip(words, scores):\n",
    "            bar = '‚ñà' * int(s * 10)\n",
    "            print(f\"  {w:10} {bar} {s:.2f}\")\n",
    "    else:\n",
    "        similar_results[word] = None\n",
    "        print(f\"  '{word}' not in vocabulary.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, len(test_words), figsize=(5 * len(test_words), 4))\n",
    "\n",
    "# Handle single-axis case\n",
    "if len(test_words) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, word in zip(axes, test_words):\n",
    "    result = similar_results[word]\n",
    "\n",
    "    if result:\n",
    "        words, scores = result\n",
    "        ax.barh(words, scores)\n",
    "        ax.set_title(f\"'{word}'\")\n",
    "        ax.set_xlabel(\"Similarity\")\n",
    "        ax.invert_yaxis()\n",
    "    else:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "fig.suptitle(\"Most Similar Words\", fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "id": "2328219e144ec03c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Diese Funktion sucht nach den **√§hnlichsten W√∂rtern** zu einem gegebenen Wort im Word2Vec-Modell.\n",
    "Sie gibt zwei Listen zur√ºck:\n",
    "\n",
    "- **`words`** ‚Üí die √§hnlichsten W√∂rter\n",
    "- **`scores`** ‚Üí die √Ñhnlichkeitswerte (Kosinus-√Ñhnlichkeit, zwischen 0 und 1)\n",
    "\n",
    "Wenn das Wort **nicht im Vokabular** vorhanden ist, wird **`(None, None)`** zur√ºckgegeben.\n",
    "\n",
    "**Ergebnis:**\n",
    "\n",
    "`happy - sad`\n",
    "\n",
    "‚Üí √úberraschend √§hnlich, obwohl es Gegenteile sind.\n",
    "**Warum?** Word2Vec versteht **Kontext√§hnlichkeit**, nicht logische Gegens√§tze.\n",
    "Beide W√∂rter treten oft in √§hnlichen Satzstrukturen auf:\n",
    "> ‚ÄúI feel happy today.‚Äù / ‚ÄúI feel sad today.‚Äù\n",
    "Daher liegen sie **r√§umlich nah**, obwohl sie **semantisch gegens√§tzlich** sind.\n",
    "\n",
    "`happy - happier`\n",
    "\n",
    "‚Üí Grammatische Variante desselben Wortstamms (‚Äûhappy‚Äú ‚Üí ‚Äûhappier‚Äú).\n",
    "Das Modell erkennt **Formverwandtschaften**.\n",
    "\n",
    "`happy - sure`\n",
    "\n",
    "‚Üí Semantische Assoziation durch **gemeinsamen Kontext**:\n",
    "> ‚Äûhappy holidays‚Äú, ‚Äûfeeling happy during holidays‚Äú\n",
    "W√∂rter, die h√§ufig **gemeinsam auftreten**, erhalten h√∂here √Ñhnlichkeitswerte.\n"
   ],
   "id": "a21be76d95ce26b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def explore_similar_words(word, model, top_n=10):\n",
    "\n",
    "    if word not in model.wv:\n",
    "        raise ValueError(f\"'{word}' not in model vocabulary.\")\n",
    "\n",
    "\n",
    "    similar = model.wv.most_similar(word, topn=top_n)\n",
    "    words = [word] + [w for w, _ in similar]\n",
    "    scores = [1.0] + [s for _, s in similar]\n",
    "\n",
    "\n",
    "    vectors = np.array([model.wv[w] for w in words])\n",
    "\n",
    "\n",
    "    if vectors.shape[1] > 3:\n",
    "        pca = PCA(n_components=3)\n",
    "        vectors_3d = pca.fit_transform(vectors)\n",
    "        axis_titles = (\"PC1\", \"PC2\", \"PC3\")\n",
    "    else:\n",
    "        vectors_3d = vectors\n",
    "        axis_titles = tuple(f\"Dim{i+1}\" for i in range(vectors.shape[1]))\n",
    "\n",
    "\n",
    "    sizes = np.array(scores) * 25\n",
    "    colors = np.array(scores)\n",
    "\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "                x=vectors_3d[:, 0],\n",
    "                y=vectors_3d[:, 1],\n",
    "                z=vectors_3d[:, 2] if vectors_3d.shape[1] > 2 else np.zeros(len(words)),\n",
    "                mode=\"markers+text\",\n",
    "                text=words,\n",
    "                textposition=\"top center\",\n",
    "                marker=dict(\n",
    "                    size=sizes,\n",
    "                    color=colors,\n",
    "                    colorscale=\"viridis\",\n",
    "                    showscale=True,\n",
    "                    colorbar=dict(title=\"Similarity\"),\n",
    "                    line=dict(width=1, color=\"black\"),\n",
    "                    symbol=[\"diamond\"] + [\"circle\"] * (len(words) - 1)\n",
    "                ),\n",
    "                hovertemplate=\"<b>%{text}</b><br>Similarity: %{marker.color:.2f}<extra></extra>\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Similar Words to '{word}' (Top {top_n}) ‚Äî Color/Size = Similarity\",\n",
    "        scene=dict(\n",
    "            xaxis_title=axis_titles[0],\n",
    "            yaxis_title=axis_titles[1],\n",
    "            zaxis_title=axis_titles[2],\n",
    "        ),\n",
    "        height=600,\n",
    "        margin=dict(l=0, r=0, t=40, b=0),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "fig = explore_similar_words(\"love\", model, top_n=30)\n",
    "fig.show()"
   ],
   "id": "9b70938a83ee29d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Analys:** Das Wort *love*\n",
    "\n",
    "Diese Funktion zeigt, **wie nah verwandte W√∂rter im semantischen Raum** zueinander liegen.\n",
    "Hier das Beispielwort **\"love\"**.\n",
    "\n",
    "| Vergleich | Distanz | Warum |\n",
    "|------------|----------|-------|\n",
    "| love ‚Üî loving | sehr gering | gleiche Wortfamilie, gleicher Kontext (Verbformen) |\n",
    "| love ‚Üî baby | etwas gr√∂√üer | thematisch √§hnlich, aber anderer Satzgebrauch |\n",
    "\n",
    "**Semantische Zonen:**\n",
    "\n",
    "| Bereich | W√∂rter | Bedeutung |\n",
    "|----------|---------|------------|\n",
    "|  **Zentrum** | love, loving, lov, loves | direkter Wortstamm (h√∂chste √Ñhnlichkeit) |\n",
    "|  **Links-Vorne** | baby, babe, darling, girl, heart | emotionale / beziehungsbezogene Substantive |\n",
    "|  **Rechts-Oben** | forever, never, always, ever | zeitliche oder abstrakte Begriffe |\n",
    "|  **Mitte** | want, feel, know, say, cause | h√§ufige Verben im emotionalen Kontext |\n",
    "|  **Unten** | believe, true | Begriffe aus dem semantischen Feld ‚ÄûVertrauen / Wahrheit‚Äú |\n",
    "\n",
    "Beispielinterpretationen:\n",
    "- `love ‚Üî loving` ‚Üí gleicher semantischer Kern, √§hnliche Satzstruktur (Verbform)\n",
    "- `love ‚Üî loves` ‚Üí gleiche Bedeutung, anderer grammatikalischer Kontext"
   ],
   "id": "64799db3ea495920"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 Embedding Space",
   "id": "74c96c74c2a8957"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def explore_embedding_space(model, n_words=30):\n",
    "    vocab = list(model.wv.index_to_key)\n",
    "    if len(vocab) == 0:\n",
    "        raise ValueError(\"The model has an empty vocabulary.\")\n",
    "    n = min(n_words, len(vocab))\n",
    "    words = vocab[:n]\n",
    "\n",
    "    vectors = np.array([model.wv[w] for w in words])\n",
    "\n",
    "    if vectors.shape[1] > 3:\n",
    "        pca = PCA(n_components=3)\n",
    "        vectors_3d = pca.fit_transform(vectors)\n",
    "        axis_titles = (\"PC1\", \"PC2\", \"PC3\")\n",
    "    else:\n",
    "        vectors_3d = vectors\n",
    "        axis_titles = tuple(f\"Dim{i+1}\" for i in range(vectors.shape[1]))\n",
    "\n",
    "    distances = np.linalg.norm(vectors_3d, axis=1)\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "                x=vectors_3d[:, 0],\n",
    "                y=vectors_3d[:, 1] if vectors_3d.shape[1] > 1 else np.zeros_like(distances),\n",
    "                z=vectors_3d[:, 2] if vectors_3d.shape[1] > 2 else np.zeros_like(distances),\n",
    "                mode=\"markers+text\",\n",
    "                text=words,\n",
    "                textposition=\"top center\",\n",
    "                marker=dict(\n",
    "                    size=np.clip(distances * 3, 4, 24),\n",
    "                    color=distances,\n",
    "                    colorscale=\"Viridis\",\n",
    "                    showscale=True,\n",
    "                    colorbar=dict(title=\"Distance\"),\n",
    "                ),\n",
    "                hovertemplate=\"<b>%{text}</b><br>Distance: %{marker.color:.2f}<extra></extra>\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Explore the Word Space (Top {n} words) ‚Äî Size/Color = Distance from Origin\",\n",
    "        scene=dict(\n",
    "            xaxis_title=axis_titles[0],\n",
    "            yaxis_title=axis_titles[1] if len(axis_titles) > 1 else \"\",\n",
    "            zaxis_title=axis_titles[2] if len(axis_titles) > 2 else \"\",\n",
    "        ),\n",
    "        height=600,\n",
    "        margin=dict(l=0, r=0, t=40, b=0),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "fig = explore_embedding_space(model, n_words=50)\n",
    "fig.show()"
   ],
   "id": "8a79c2ec5b7dfe73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**3D-Visualisierung der Wortvektoren:**\n",
    "\n",
    "Diese Funktion erzeugt eine **3D-Visualisierung** der Wortvektoren aus dem trainierten Word2Vec-Modell.\n",
    "\n",
    "Da Word2Vec-Vektoren meist **50‚Äì300 Dimensionen** haben, wird eine **Hauptkomponentenanalyse (PCA)** durchgef√ºhrt,\n",
    "um die Daten auf **3 Dimensionen** zu reduzieren.\n",
    "\n",
    "**Funktionsweise:**\n",
    "\n",
    "- Berechnet f√ºr jedes Wort den **Abstand vom Ursprung (0, 0, 0)** im 3D-Raum.\n",
    "- Farbe und Gr√∂√üe der Punkte basieren auf diesem Abstand.\n",
    "- W√∂rter mit √§hnlicher Bedeutung oder gleichem Kontext liegen **nah beieinander**.\n",
    "\n",
    "| Aspekt | Bedeutung |\n",
    "|--------|------------|\n",
    "| **Position** | Semantische Lage im Raum ‚Äî W√∂rter mit √§hnlichem Kontext liegen nah beieinander |\n",
    "| **Abstand** | Ma√ü f√ºr semantische √Ñhnlichkeit ‚Äî je n√§her, desto √§hnlicher |\n",
    "| **Farbe** | basiert auf Distanz vom Ursprung (Dunkelblau = nah, Gelb/Gr√ºn = weit entfernt) |\n",
    "| **Gr√∂√üe** | proportional zur Distanz ‚Äî gr√∂√üere Punkte = auff√§lligere, semantisch ausgepr√§gte W√∂rter |\n",
    "\n",
    "**Beispielhafte Cluster**\n",
    "\n",
    "- **Linke Seite:** ‚Äûcome‚Äú, ‚Äûlet‚Äú, ‚Äûgo‚Äú, ‚Äûhere‚Äú, ‚Äûright‚Äú, ‚Äûwhere‚Äú, ‚Äûback‚Äú ‚Üí Funktions- oder Aktionsverben\n",
    "- **Rechte Seite:** ‚Äûbitch‚Äú, ‚Äûfuck‚Äú, ‚Äûshit‚Äú ‚Üí Vulg√§r- / Emotionalkontext\n",
    "- **Zentrum:** ‚Äûbaby‚Äú, ‚Äûlove‚Äú, ‚Äûwanna‚Äú, ‚Äûthink‚Äú ‚Üí emotionale, umgangssprachliche W√∂rter\n",
    "\n",
    "Das Modell hat gelernt, dass bestimmte Wortgruppen √§hnliche Verwendungen haben,\n",
    "selbst wenn ihre **Bedeutung unterschiedlich** ist."
   ],
   "id": "1199b91ed780cce5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T16:43:32.219159Z",
     "start_time": "2025-10-23T16:43:32.213080Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "Die Funktion **`explore_doc_space()`** zeigt,\n",
    "**wie √§hnlich oder unterschiedlich Songtexte zueinander sind**, basierend auf ihren **Embeddings**.\n",
    "\n",
    "- Jeder Punkt = ein **Song (Dokument)**\n",
    "- **N√§he zweier Punkte** ‚Üí √§hnliche Wortverwendungen oder Themen\n",
    "- **Farbe & Gr√∂√üe** ‚Üí Distanz vom Ursprung (semantische ‚ÄûCharakteristik‚Äú des Songs)\n",
    "- **Cluster** ‚Üí Gruppen von Songs mit √§hnlichem Inhalt, Stimmung oder Vokabular\n",
    "\n",
    " Damit wird sichtbar, **welche Songs sich thematisch √§hneln**,\n",
    "> z. B. Liebeslieder, Partytracks oder melancholische Texte."
   ],
   "id": "1b199e2299133fe8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. TF-IDF",
   "id": "54145f10026d4762"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tfidf_vect = TfidfVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    lowercase=False\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf_vect.fit_transform(df[\"tokens\"])\n",
    "terms = tfidf_vect.get_feature_names_out()\n",
    "\n",
    "dim = model.wv.vector_size\n",
    "doc_emb_tfidf = np.zeros((X_tfidf.shape[0], dim), dtype=np.float32)\n",
    "\n",
    "for i in range(X_tfidf.shape[0]):\n",
    "    row = X_tfidf[i]\n",
    "    if row.nnz == 0:\n",
    "        continue\n",
    "    idxs = row.indices\n",
    "    wts = row.data\n",
    "    vecs = []\n",
    "    w = []\n",
    "    for j, wt in zip(idxs, wts):\n",
    "        term = terms[j]\n",
    "        if term in model.wv:\n",
    "            vecs.append(model.wv[term])\n",
    "            w.append(wt)\n",
    "    if w:\n",
    "        vecs = np.vstack(vecs)\n",
    "        w = np.asarray(w, dtype=np.float32)\n",
    "        doc_emb_tfidf[i] = (vecs * w[:, None]).sum(axis=0) / (w.sum() + 1e-9)\n",
    "\n",
    "print(\"TF-IDF-Embeddings:\", doc_emb_tfidf.shape)\n",
    "\n",
    "# Optional: Nullvektoren rausfiltern (falls ein Song keine bekannten W√∂rter hat)\n",
    "keep = np.linalg.norm(doc_emb_tfidf, axis=1) > 0\n",
    "df_use = df.reset_index(drop=True).loc[keep].reset_index(drop=True)\n",
    "emb_use = doc_emb_tfidf[keep]\n",
    "print(\"Nach Filter:\", emb_use.shape)"
   ],
   "id": "bb5760827393342c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Dokument-Vektoren mit Word2Vec & TF-IDF**\n",
    "\n",
    "**Ziel**\n",
    "F√ºr jedes Dokument (z. B. Songtext) wird ein **repr√§sentativer Vektor** berechnet,\n",
    "der die Bedeutung aller W√∂rter kombiniert ‚Äì **gewichtet nach ihrer Wichtigkeit**.\n",
    "\n",
    "**Einstellungen**\n",
    "| Parameter | Bedeutung |\n",
    "|------------|------------|\n",
    "| `tokenizer=lambda x: x` | Verwendet die vorhandene Tokenliste (nicht erneut splitten) |\n",
    "| `preprocessor=lambda x: x` | Kein Text-Cleaning oder Joinen |\n",
    "| `token_pattern=None` | Deaktiviert die Standardtokenizer-Regel von sklearn |\n",
    "| `lowercase=False` | Tokens bleiben in ihrer urspr√ºnglichen Form (Gro√ü-/Kleinschreibung bleibt erhalten) |\n",
    "\n",
    "**Konzept**\n",
    "- **Word2Vec** ‚Üí f√§ngt **semantische Beziehungen** zwischen W√∂rtern ein\n",
    "- **TF-IDF (Term Frequency ‚Äì Inverse Document Frequency)** ‚Üí hebt **wichtige W√∂rter** hervor"
   ],
   "id": "6cf19f65f03ced12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Embedding of whole songs",
   "id": "66ef15d4878e475d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "GENRE_COL = \"tag\"\n",
    "\n",
    "def get_song_vector(tokens, w2v_model):\n",
    "    \"\"\"\n",
    "    Compute a single vector representation for one song by\n",
    "    averaging all word vectors for its tokens.\n",
    "    If no token is in the vocabulary, return a zero vector.\n",
    "    \"\"\"\n",
    "    if not isinstance(tokens, (list, tuple)):\n",
    "        return np.zeros(w2v_model.vector_size, dtype=np.float32)\n",
    "\n",
    "    vectors = [w2v_model.wv[t] for t in tokens if t in w2v_model.wv]\n",
    "\n",
    "    if not vectors:\n",
    "        return np.zeros(w2v_model.vector_size, dtype=np.float32)\n",
    "\n",
    "    return np.mean(vectors, axis=0).astype(np.float32)\n",
    "\n",
    "# Keep only rows that have tokens and a genre label\n",
    "df_songs = df.dropna(subset=[\"tokens\", GENRE_COL]).copy()\n",
    "\n",
    "# Compute one embedding per song\n",
    "df_songs[\"embedding\"] = df_songs[\"tokens\"].apply(\n",
    "    lambda toks: get_song_vector(toks, model)\n",
    ")\n",
    "\n",
    "# Stack into feature matrix X and label array y\n",
    "X = np.vstack(df_songs[\"embedding\"].values)        # shape: (n_songs, embedding_dim)\n",
    "y = df_songs[GENRE_COL].astype(str).values         # shape: (n_songs,)\n",
    "\n",
    "print(\"Song embeddings shape:\", X.shape)\n",
    "print(\"Number of songs:\", len(y))\n",
    "print(\"Example genres:\", y[:10])\n"
   ],
   "id": "adbc8bac5fe1cf20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def explore_doc_space(embeddings, labels=None, n_max=None):\n",
    "    \"\"\"\n",
    "    Interaktiver 3D-Plot von Dokument-/Song-Embeddings.\n",
    "    Nutzt ggf. PCA auf 3 Dimensionen und f√§rbt/skalieren nach Distanz vom Ursprung.\n",
    "    \"\"\"\n",
    "\n",
    "    if embeddings is None or len(embeddings) == 0:\n",
    "        raise ValueError(\"Keine Embeddings √ºbergeben.\")\n",
    "\n",
    "    X = np.asarray(embeddings)\n",
    "    if n_max is not None:\n",
    "        X = X[:n_max]\n",
    "        if labels is not None:\n",
    "            labels = labels[:n_max]\n",
    "\n",
    "    # Auf 3 Dimensionen reduzieren (falls n√∂tig)\n",
    "    if X.shape[1] > 3:\n",
    "        pca = PCA(n_components=3)\n",
    "        X3 = pca.fit_transform(X)\n",
    "        axis_titles = (\"PC1\", \"PC2\", \"PC3\")\n",
    "    else:\n",
    "        X3 = X\n",
    "        axis_titles = tuple(f\"Dim{i+1}\" for i in range(X.shape[1]))\n",
    "        # ggf. auf 3 Achsen auff√ºllen\n",
    "        if X3.shape[1] == 1:\n",
    "            X3 = np.hstack([X3, np.zeros((X3.shape[0], 2))])\n",
    "        elif X3.shape[1] == 2:\n",
    "            X3 = np.hstack([X3, np.zeros((X3.shape[0], 1))])\n",
    "\n",
    "    # Distanz vom Ursprung ‚Üí f√ºr Marker-Gr√∂√üe/Farbe\n",
    "    distances = np.linalg.norm(X3, axis=1)\n",
    "\n",
    "    if labels is None:\n",
    "        labels = [f\"Doc {i}\" for i in range(X3.shape[0])]\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "                x=X3[:, 0],\n",
    "                y=X3[:, 1],\n",
    "                z=X3[:, 2],\n",
    "                mode=\"markers+text\",\n",
    "                text=labels,\n",
    "                textposition=\"top center\",\n",
    "                marker=dict(\n",
    "                    size=np.clip(distances * 3, 4, 24),\n",
    "                    color=distances,\n",
    "                    colorscale=\"Viridis\",\n",
    "                    showscale=True,\n",
    "                    colorbar=dict(title=\"Distance\"),\n",
    "                    opacity=0.9,\n",
    "                ),\n",
    "                hovertemplate=\"<b>%{text}</b><extra></extra>\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Explore the Song Space ‚Äî Size/Color = Distance from Origin\",\n",
    "        scene=dict(\n",
    "            xaxis_title=axis_titles[0],\n",
    "            yaxis_title=axis_titles[1] if len(axis_titles) > 1 else \"\",\n",
    "            zaxis_title=axis_titles[2] if len(axis_titles) > 2 else \"\",\n",
    "        ),\n",
    "        height=650,\n",
    "        margin=dict(l=0, r=0, t=40, b=0),\n",
    "    )\n",
    "    return fig"
   ],
   "id": "6b1145c9625fe67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embeddings = X  # shape: (n_songs, embedding_dim)\n",
    "\n",
    "# Labels f√ºr den Plot: bevorzugt Titel, sonst Tag, sonst Index\n",
    "df_use = df_songs.copy()\n",
    "\n",
    "labels = None\n",
    "for col in [\"title\", \"artist\", \"tag\"]:\n",
    "    if col in df_use.columns:\n",
    "        labels = df_use[col].astype(str).tolist()\n",
    "        break\n",
    "\n",
    "if labels is None:\n",
    "    labels = df_use.index.astype(str).tolist()\n",
    "\n",
    "# 25 Songs plotten (die ersten 25 in df_songs/X)\n",
    "fig_docs = explore_doc_space(embeddings, labels=labels, n_max=40)\n",
    "fig_docs.show()"
   ],
   "id": "c3bee5770503d056",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pca = PCA(n_components=3, random_state=42)\n",
    "X_3d = pca.fit_transform(X)\n",
    "\n",
    "# Build a DataFrame for plotting\n",
    "df_plot = pd.DataFrame({\n",
    "    \"pc1\": X_3d[:, 0],\n",
    "    \"pc2\": X_3d[:, 1],\n",
    "    \"pc3\": X_3d[:, 2],\n",
    "    \"genre\": y.astype(str)\n",
    "})\n",
    "\n",
    "# viridis colors\n",
    "viridis_256 = px.colors.sample_colorscale(\"Viridis\", np.linspace(0, 1, 6))\n",
    "\n",
    "# Interactive 3D scatter plot with Plotly\n",
    "fig = px.scatter_3d(\n",
    "    df_plot,\n",
    "    x=\"pc1\",\n",
    "    y=\"pc2\",\n",
    "    z=\"pc3\",\n",
    "    color=\"genre\",\n",
    "    opacity=0.3,\n",
    "    title=\"Songs in Word2Vec embedding space (PCA 3D)\",\n",
    "    color_discrete_sequence=viridis_256\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=4))\n",
    "fig.show()"
   ],
   "id": "f97a3c7e56e89a40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Save Model",
   "id": "921ad0f737b7ce0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1) Save feature matrix X and label vector y\n",
    "os.makedirs(\"data/features\", exist_ok=True)\n",
    "\n",
    "np.save(\"data/features/song_embeddings.npy\", X)\n",
    "np.save(\"data/features/song_labels.npy\", y)\n",
    "\n",
    "print(\"Saved song embeddings and labels to 'data/features/'\")\n",
    "\n",
    "# 2) Save metadata (optional but very useful)\n",
    "meta_cols = [GENRE_COL]\n",
    "for col in [\"title\", \"artist\", \"id\", \"song_id\"]:\n",
    "    if col in df_songs.columns:\n",
    "        meta_cols.append(col)\n",
    "\n",
    "df_songs[meta_cols].to_csv(\"data/features/song_metadata.csv\", index=False)\n",
    "print(\"Saved song metadata to 'data/features/song_metadata.csv'\")\n",
    "\n",
    "# 3) Save the trained Word2Vec model\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model.save(\"models/word2vec_lyrics.model\")\n",
    "print(\"Saved Word2Vec model to 'models/word2vec_lyrics.model'\")\n"
   ],
   "id": "82ec28980addff05",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
